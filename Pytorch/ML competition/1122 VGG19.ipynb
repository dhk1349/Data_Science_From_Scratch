{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.2)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): LeakyReLU(negative_slope=0.2)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): LeakyReLU(negative_slope=0.2)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): LeakyReLU(negative_slope=0.2)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): LeakyReLU(negative_slope=0.2)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): LeakyReLU(negative_slope=0.2)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): LeakyReLU(negative_slope=0.2)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): LeakyReLU(negative_slope=0.2)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): LeakyReLU(negative_slope=0.2)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avg_pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (classifier): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "Number of parameters: 15227688\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #3 224 128\n",
    "            nn.Conv2d(3, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #64 112 64\n",
    "            nn.Conv2d(64, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #128 56 32\n",
    "            nn.Conv2d(128, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #256 28 16\n",
    "            nn.Conv2d(256, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #512 14 8\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #512 7 4\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "        #512 1 1\n",
    "        self.classifier = nn.Linear(512, 1000)\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(512*2*2,4096)\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,10)\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        features = self.conv(x)\n",
    "        #print(features.size())\n",
    "        x = self.avg_pool(features)\n",
    "        #print(avg_pool.size())\n",
    "        x = x.view(features.size(0), -1)\n",
    "        #print(flatten.size())\n",
    "        x = self.classifier(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x, features\n",
    "    \n",
    "net = Net()\n",
    "print(net)\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Number of parameters: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrink_VGG(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): LeakyReLU(negative_slope=0.2)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=10)\n",
      ")\n",
      "Number of parameters: 1708810\n",
      "0 1728\n",
      "1 64\n",
      "2 73728\n",
      "3 128\n",
      "4 147456\n",
      "5 128\n",
      "6 294912\n",
      "7 256\n",
      "8 589824\n",
      "9 256\n",
      "10 589824\n",
      "11 256\n",
      "12 10240\n",
      "13 10\n"
     ]
    }
   ],
   "source": [
    "class Shrink_VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shrink_VGG, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #3 224 128\n",
    "            nn.Conv2d(3, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(64, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #64 112 64\n",
    "            nn.Conv2d(64, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #128 56 32\n",
    "            nn.Conv2d(128, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #256 28 16\n",
    "            #nn.Conv2d(256, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.MaxPool2d(2, 2)\n",
    "            #512 14 8\n",
    "            #nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            #nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #512 7 4\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(2)\n",
    "        #512 1 1\n",
    "        #self.classifier = nn.Linear(512, 1000)\n",
    "        \n",
    "        \n",
    "        #self.fc1 = nn.Linear(512*1*1,512)\n",
    "        #self.fc2 = nn.Linear(2048,2048)\n",
    "        self.fc3 = nn.Linear(1024,10)\n",
    "        self.softmax=nn.Softmax(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        features = self.conv(x)\n",
    "        print(\"1\", features.size())\n",
    "        x = self.avg_pool(features)\n",
    "        print(\"2\", x.size())\n",
    "        x = x.view(features.size(0), -1)\n",
    "        #print(flatten.size())\n",
    "        print(\"3\", x.size())\n",
    "        #x = self.classifier(x)\n",
    "        #x = self.softmax(x)\n",
    "        #x=self.fc1(x)\n",
    "        #x=self.fc2(x)\n",
    "        x=self.fc3(x)\n",
    "        return x, features\n",
    "    \n",
    "net = Shrink_VGG()\n",
    "print(net)\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Number of parameters: {pytorch_total_params}\")\n",
    "for idx, p in enumerate(net.parameters()):\n",
    "    print(idx, p.numel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=Variable(torch.randn(1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([1, 256, 4, 4])\n",
      "2 torch.Size([1, 256, 2, 2])\n",
      "3 torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "output=net(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 4, 4])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0213, -0.0173, -0.0105, -0.0060,  0.0189, -0.0027, -0.0057,  0.0315,\n",
       "          0.0082,  0.0034]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
