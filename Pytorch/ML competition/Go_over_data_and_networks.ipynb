{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "        #self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.size())\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [3, 3, 1, 1])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    r\"\"\"Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def print(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # _, pred = output.topk(maxk, 1, True, True)\n",
    "        # pred = pred.t()\n",
    "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
    "        _, idx = output.sort(descending=True)\n",
    "        pred = idx[:,:maxk]\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        \"\"\"\n",
    "        print(\"size of pred and correct in acc fnc: \", pred.size(), correct.size(), target.view(1, -1).expand_as(pred).size())\n",
    "        print(pred, target.view(1, -1).expand_as(pred))\n",
    "        \"\"\"\n",
    "        label=torch.zeros(10)\n",
    "        res = []\n",
    "        cat_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "        deer_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "        dog_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "        _target=target.view(1, -1).expand_as(pred).squeeze().cpu().detach().numpy() \n",
    "        _pred=pred.squeeze().cpu().detach().numpy() \n",
    "        for idx, i in enumerate(correct.squeeze()):\n",
    "            if i==False:\n",
    "                label[_target[idx]]+=1\n",
    "                \n",
    "                if _target[idx]==3:\n",
    "                    cat_label[_pred[idx]]+=1\n",
    "                elif _target[idx]==4:\n",
    "                    deer_label[_pred[idx]]+=1\n",
    "                elif _target[idx]==5:\n",
    "                    dog_label[_pred[idx]]+=1\n",
    "                \n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res, label, cat_label, deer_label, dog_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEPATH = './weight/1130resnet/'\n",
    "WEIGHTDECAY = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCHSIZE = 256\n",
    "LR = 0.1\n",
    "EPOCHS = 1000\n",
    "PRINTFREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1974090\n",
      "==================================================\n",
      "tensor([1033., 1298., 1638., 2342., 2162., 2820.,  901., 1347., 1097., 1670.])\n",
      "total number of wrong samples:  tensor(16308.)\n",
      "cat label:  {0: 82, 1: 28, 2: 342, 3: 0, 4: 348, 5: 1007, 6: 324, 7: 88, 8: 78, 9: 45}\n",
      "deer label:  {0: 77, 1: 22, 2: 385, 3: 397, 4: 0, 5: 549, 6: 147, 7: 456, 8: 102, 9: 27}\n",
      "dog label:  {0: 65, 1: 50, 2: 375, 3: 1093, 4: 569, 5: 0, 6: 161, 7: 359, 8: 98, 9: 50}\n",
      "Number of parameters: 1974090\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def main():\n",
    "   model = ResNet18()\n",
    "\n",
    "   model = model.cuda()\n",
    "\n",
    "   model.load_state_dict(torch.load(\"./weight/1130resnet/\"+'earlystop_check_best.pth'))\n",
    "\n",
    "   # Check number of parameters your model\n",
    "   pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "   print(f\"Number of parameters: {pytorch_total_params}\")\n",
    "   \n",
    "   if int(pytorch_total_params) > 2000000:\n",
    "       print('Your model has the number of parameters more than 2 millions..')\n",
    "       return\n",
    "   \n",
    "   normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "   \"\"\"\n",
    "   train_transform = transforms.Compose([\n",
    "       transforms.RandomCrop(32, padding=4),\n",
    "       transforms.RandomHorizontalFlip(),\n",
    "       transforms.RandomAffine(30),\n",
    "       transforms.ColorJitter(brightness=(0.2, 2), contrast=(0.3, 2), saturation=(0.2, 2), hue=(-0.3, 0.3)), \n",
    "       transforms.ToTensor(),\n",
    "       normalize, \n",
    "   ])\n",
    "   \n",
    "   train_dataset = torchvision.datasets.ImageFolder(\n",
    "       '/home/dhk1349/Desktop/Machine Learning/train', transform=train_transform)\n",
    "   train_loader = DataLoader(train_dataset,\n",
    "                             batch_size=BATCHSIZE , shuffle=True,\n",
    "                             num_workers=4, pin_memory=True)\n",
    "   \"\"\" \n",
    "\n",
    "\n",
    "   valid_transform = transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       normalize\n",
    "   ])\n",
    "    \n",
    "   fake_train_dataset = torchvision.datasets.ImageFolder(\n",
    "       '/home/dhk1349/Desktop/Machine Learning/train', transform=valid_transform)\n",
    "\n",
    "   val_dataset = torchvision.datasets.ImageFolder('/home/dhk1349/Desktop/Machine Learning/valid', transform=valid_transform)\n",
    "   val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "   #val_loader = DataLoader(fake_train_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "   last_top1_acc = 0\n",
    "\n",
    "   # LOSS FOR EARLY STOPPING\n",
    "   best_valid_loss = float('inf')\n",
    "   early_stop_check = 0\n",
    "\n",
    "   for epoch in range(1):\n",
    "       \n",
    "       valid_acc, total_list, cat, deer, dog = valid(val_loader, epoch, model)\n",
    "      \n",
    "        \n",
    "       #print(f'\\t==Valid Loss: {valid_loss:.3f} | Valid acc: {valid_acc:.3f}==\\n')\n",
    "       \n",
    "   print(\"==================================================\")\n",
    "   print(total_list)\n",
    "   print(\"total number of wrong samples: \", total_list.sum())\n",
    "\n",
    "   print(\"cat label: \", cat)\n",
    "   print(\"deer label: \", deer)\n",
    "   print(\"dog label: \", dog)\n",
    "    \n",
    "   #print(f\"Last Top-1 Accuracy: {last_top1_acc}\")\n",
    "   print(f\"Number of parameters: {pytorch_total_params}\")\n",
    "\n",
    "\n",
    "\n",
    "def valid(val_loader, epoch, model):\n",
    "   # LOSS FOR EARLYSTOPPPING\n",
    "   total_loss = 0\n",
    "   iter_num = 0\n",
    "   val_acc = 0\n",
    "   total_list=torch.zeros(10)\n",
    "   with torch.no_grad():\n",
    "     total_cat_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "     total_deer_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "     total_dog_label={0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "     for i, (input, target) in enumerate(val_loader):\n",
    "       input = input.cuda()\n",
    "       target = target.cuda()\n",
    "\n",
    "       output = model(input)\n",
    "       #loss = criterion(output, target)\n",
    "       acc1, result_lst, cat, deer, dog = accuracy(output, target, topk=(1,))\n",
    "       \n",
    "       total_list+=result_lst\n",
    "        \n",
    "       for idx, i in enumerate(cat.values()):\n",
    "          total_cat_label[idx]+=i\n",
    "       for idx, i in enumerate(deer.values()):\n",
    "          total_deer_label[idx]+=i\n",
    "       for idx, i in enumerate(dog.values()):\n",
    "          total_dog_label[idx]+=i\n",
    "       #print(total_list)\n",
    "       #total_loss += loss.item()\n",
    "       iter_num += 1\n",
    "       val_acc += acc1[0].item()\n",
    "\n",
    "     return  val_acc / iter_num, total_list, total_cat_label, total_deer_label, total_dog_label\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
