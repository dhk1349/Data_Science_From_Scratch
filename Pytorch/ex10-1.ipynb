{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture09_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s0afLGkF8lB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGhsIFDkGSP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e4b48b-9964-47e8-f7ab-63aa32150bc2"
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# Training settings\n",
        "batch_size = 64\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "class LocallyConnected2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, output_size, kernel_size, stride, bias=False):\n",
        "        super(LocallyConnected2d, self).__init__()\n",
        "        output_size = _pair(output_size)\n",
        "        self.weight = nn.Parameter(\n",
        "            torch.randn(1, out_channels, in_channels, output_size[0], output_size[1], kernel_size**2)\n",
        "        )\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(\n",
        "                torch.randn(1, out_channels, output_size[0], output_size[1])\n",
        "            )\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.kernel_size = _pair(kernel_size)\n",
        "        self.stride = _pair(stride)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        _, c, h, w = x.size()\n",
        "        kh, kw = self.kernel_size\n",
        "        dh, dw = self.stride\n",
        "        x = x.unfold(2, kh, dh).unfold(3, kw, dw)\n",
        "        x = x.contiguous().view(*x.size()[:-2], -1)\n",
        "        # Sum in in_channel and kernel_size dims\n",
        "        out = (x.unsqueeze(1) * self.weight).sum([2, -1])\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "in_channels = 3\n",
        "h, w = 24, 24\n",
        "\n",
        "output_size = 22\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1=nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2=nn.Conv2d(10,20, kernel_size=3, padding=1)\n",
        "        self.conv3=nn.Conv2d(20,30, kernel_size=3, padding=1)\n",
        "        self.local=LocallyConnected2d(30, 40, 22, 3, 1, bias=True)\n",
        "        self.mp=nn.MaxPool2d(2)\n",
        "        self.fc1=nn.Linear(19360, 1024)\n",
        "        self.fc2=nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size=x.size(0)\n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        #print(\"1\",x.size())\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        #print(\"2\",x.size())\n",
        "        x = F.relu(self.mp(self.conv3(x)))\n",
        "        x=self.local(x)\n",
        "        #print(\"3\", x.size())\n",
        "        x = x.view(in_size, -1)\n",
        "        #print(\"4\", x.size())\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).item()\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST Model on cuda\n",
            "============================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.417682\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 142.515106\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 8503.079102\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 19265.632812\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2055.636719\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 1266.393188\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 784.220947\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 649.270508\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 476.980255\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 249.833191\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 162.226379\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 70.106705\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 100.403236\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 55.751686\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 40.573177\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 60.240273\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 36.620136\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 22.269543\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 14.585619\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 12.825416\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 11.447840\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 28.298250\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 20.525473\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 13.849571\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 9.492439\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 8.894936\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 16.635450\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 9.849099\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 7.848108\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 9.304854\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 5.142302\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 15.971690\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 7.483742\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 8.196123\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 8.180306\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 3.417985\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 7.171613\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 7.168878\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 5.345108\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 3.376236\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 5.479343\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 4.310997\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.795673\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.342939\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.681165\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 3.186915\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 4.488656\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.421763\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 4.927623\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.485687\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 4.561297\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 3.015857\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 3.683255\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 3.680791\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.480554\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.696015\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 3.421082\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 3.061407\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.850863\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 3.144133\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 4.549125\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.836194\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.461878\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.308861\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 3.465705\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.388400\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.314625\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.480386\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 3.531811\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.621960\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.421402\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 3.064963\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.817433\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.373292\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.351018\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.329673\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 3.517448\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.419791\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.303398\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.543987\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.515833\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.635544\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.328412\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.444537\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.835151\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.941669\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.487086\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 2.439208\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 2.990462\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 2.394601\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 2.399141\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 2.491142\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 2.772268\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 2.319890\n",
            "Training time: 1m 4s\n",
            "===========================\n",
            "Test set: Average loss: 0.0383, Accuracy: 892/10000 (9%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 2.522626\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 2.371916\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 2.545676\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 2.339895\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 2.425725\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 2.393176\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 2.330705\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 2.558929\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 2.331533\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 2.372077\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 2.319815\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 2.295185\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 2.350734\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 2.369510\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 2.368879\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 2.310403\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 2.550606\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 2.299620\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 2.436719\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 2.340401\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 2.303728\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 2.421843\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 2.887045\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 2.301821\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 2.310594\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 2.673741\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 2.281606\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 2.300770\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 2.343327\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 2.862884\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 2.318361\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 2.327988\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 2.334453\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 2.408900\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 2.281065\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 2.339401\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 2.421481\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 2.283998\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 2.406954\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 2.462091\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 2.333756\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 2.422783\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 2.689619\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 2.338038\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 2.321547\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 2.556461\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 2.306111\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 2.336497\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 2.322160\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 2.312806\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 2.482108\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 2.374633\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 2.454264\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 2.343624\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 2.324008\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 2.653481\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 2.452679\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 2.315810\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 2.480632\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 2.360989\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 2.489146\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 2.393402\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 2.362187\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 2.404362\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 2.397980\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 2.305404\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 2.762358\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 2.316220\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 2.318671\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 2.312154\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 2.318338\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 2.294375\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 2.384567\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 2.469880\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 2.418001\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 2.337203\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 2.490571\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 2.342780\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 2.368643\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 2.320143\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 2.365984\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 2.320482\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 2.341897\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 2.300608\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 2.346607\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 2.387062\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 2.384925\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 2.343760\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 2.302068\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 2.303630\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 2.332807\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 2.291373\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 2.298203\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 2.329862\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0373, Accuracy: 980/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 2.370043\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 2.324455\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 2.361352\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 2.439102\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 2.312262\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 2.326848\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 2.279011\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 2.299900\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 2.306820\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 2.306543\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 2.373467\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 2.328162\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 2.333323\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 2.286388\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 2.381409\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 2.331546\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 2.320729\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 2.345074\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 2.306578\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 2.302014\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 2.343851\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 2.316608\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 2.323600\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 2.317330\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 2.307366\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 2.385032\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 2.287206\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 2.294355\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 2.314134\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 2.351454\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 2.348548\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 2.314499\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 2.318519\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 2.276524\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 2.330287\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 2.305556\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 2.360790\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 2.354776\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 2.355033\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 2.383435\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 2.307702\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 2.342924\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 2.322884\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 2.304997\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 2.364556\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 2.356986\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 2.356437\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 2.314827\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 2.335839\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 2.376463\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 2.327924\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 2.345370\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 2.304573\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 2.317419\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 2.400997\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 2.273490\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 2.285454\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 2.362603\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 2.375003\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 2.350847\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 2.299734\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 2.292141\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 2.332662\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 2.310796\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 2.295860\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 2.285686\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 2.424596\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 2.298499\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 2.392610\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 2.379878\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 2.305076\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 2.377994\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 2.331549\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 2.333525\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 2.306715\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 2.319517\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 2.318510\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 2.397500\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 2.318311\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 2.279872\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 2.280555\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 2.420779\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 2.326108\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 2.302767\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 2.319736\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 2.307535\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 2.349323\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 2.299790\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 2.316466\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 2.299616\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 2.375947\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 2.340077\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 2.359619\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 2.360149\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0365, Accuracy: 1135/10000 (11%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 2.369173\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 2.368737\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 2.289419\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 2.336391\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 2.363986\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 2.314343\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 2.515249\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 2.338249\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 2.350270\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 2.315574\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 2.370631\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 2.323658\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 2.304513\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 2.306888\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 2.333023\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 2.313194\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 2.643309\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 2.265575\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 2.334213\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 2.335887\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 2.309026\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 2.413771\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 2.565678\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 2.328416\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 2.304642\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 2.343277\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 2.469530\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 2.296890\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 2.327885\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 2.335621\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 2.293695\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 2.374851\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 2.312046\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 2.312746\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 2.473565\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 2.297796\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 2.404304\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 2.295679\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 2.386620\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 2.312457\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 2.325675\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 2.332873\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 2.298338\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 2.340050\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 2.325497\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 2.308711\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 2.306164\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 2.373764\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 2.318452\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 2.320457\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 2.430262\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 2.316312\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 2.346605\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 2.321134\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 2.291870\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 2.492997\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 2.289527\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 2.327103\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 2.310063\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 2.407665\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 2.344595\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 2.336271\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 2.284863\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 2.377605\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 2.348577\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 2.305241\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 2.301263\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 2.347426\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 2.303237\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 2.330864\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 2.292605\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 2.306937\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 2.352061\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 2.427465\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 2.347185\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 2.316916\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 2.374907\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 2.309600\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 2.295172\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 2.298486\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 2.327580\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 2.359175\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 2.310026\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 2.332075\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 2.311025\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 2.317637\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 2.329890\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 2.303118\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 2.331242\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 2.302663\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 2.320419\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 2.316988\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 2.268447\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 2.371142\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0371, Accuracy: 980/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 2.402836\n",
            "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 2.327738\n",
            "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 2.316923\n",
            "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 2.347719\n",
            "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 2.330960\n",
            "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 2.386487\n",
            "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 2.347492\n",
            "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 2.309059\n",
            "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 2.291137\n",
            "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 2.309984\n",
            "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 2.315873\n",
            "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 2.317821\n",
            "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 2.302469\n",
            "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 2.297659\n",
            "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 2.316984\n",
            "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 2.276947\n",
            "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 2.320980\n",
            "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 2.292502\n",
            "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 2.315676\n",
            "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 2.375242\n",
            "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 2.336396\n",
            "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 2.324188\n",
            "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 2.318648\n",
            "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 2.364899\n",
            "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 2.293783\n",
            "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 2.321181\n",
            "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 2.335033\n",
            "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 2.303035\n",
            "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 2.293106\n",
            "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 2.319111\n",
            "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 2.359249\n",
            "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 2.274539\n",
            "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 2.249335\n",
            "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 2.294352\n",
            "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 2.313091\n",
            "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 2.381574\n",
            "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 2.333350\n",
            "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 2.311989\n",
            "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 2.278082\n",
            "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 2.349448\n",
            "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 2.307578\n",
            "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 2.295363\n",
            "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 2.282735\n",
            "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 2.355388\n",
            "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 2.382664\n",
            "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 2.292387\n",
            "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 2.309687\n",
            "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 2.342728\n",
            "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 2.283474\n",
            "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 2.332951\n",
            "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 2.311189\n",
            "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 2.310138\n",
            "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 2.316964\n",
            "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 2.329013\n",
            "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 2.304295\n",
            "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 2.321290\n",
            "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 2.306750\n",
            "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 2.322693\n",
            "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 2.302952\n",
            "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 2.320948\n",
            "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 2.307028\n",
            "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 2.315240\n",
            "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 2.304492\n",
            "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 2.324872\n",
            "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 2.330411\n",
            "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 2.312309\n",
            "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 2.305841\n",
            "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 2.320017\n",
            "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 2.337980\n",
            "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 2.359010\n",
            "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 2.316055\n",
            "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 2.302827\n",
            "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 2.314925\n",
            "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 2.314371\n",
            "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 2.321795\n",
            "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 2.320579\n",
            "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 2.320741\n",
            "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 2.329451\n",
            "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 2.336801\n",
            "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 2.335061\n",
            "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 2.296645\n",
            "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 2.330695\n",
            "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 2.302065\n",
            "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 2.312905\n",
            "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 2.333439\n",
            "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 2.357543\n",
            "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 2.351585\n",
            "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 2.371547\n",
            "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 2.309861\n",
            "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 2.317528\n",
            "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 2.275082\n",
            "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 2.303321\n",
            "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 2.475297\n",
            "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 2.336946\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0366, Accuracy: 974/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 2.338914\n",
            "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 2.294904\n",
            "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 2.311057\n",
            "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 2.331976\n",
            "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 2.311549\n",
            "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 2.362692\n",
            "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 2.371734\n",
            "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 2.306655\n",
            "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 2.312930\n",
            "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 2.320416\n",
            "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 2.330800\n",
            "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 2.325601\n",
            "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 2.277948\n",
            "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 2.330303\n",
            "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 2.339717\n",
            "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 2.327136\n",
            "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 2.298317\n",
            "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 2.325677\n",
            "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 2.322989\n",
            "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 2.401831\n",
            "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 2.358879\n",
            "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 2.317411\n",
            "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 2.304452\n",
            "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 2.306652\n",
            "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 2.297406\n",
            "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 2.319174\n",
            "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 2.326958\n",
            "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 2.350972\n",
            "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 2.315322\n",
            "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 2.279577\n",
            "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 2.289674\n",
            "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 2.316676\n",
            "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 2.321660\n",
            "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 2.319448\n",
            "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 2.318142\n",
            "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 2.310656\n",
            "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 2.312544\n",
            "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 2.323166\n",
            "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 2.312944\n",
            "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 2.342502\n",
            "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 2.331486\n",
            "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 2.326389\n",
            "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 2.303868\n",
            "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 2.273520\n",
            "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 2.373906\n",
            "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 2.318902\n",
            "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 2.305057\n",
            "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 2.290241\n",
            "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 2.314262\n",
            "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 2.320956\n",
            "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 2.334356\n",
            "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 2.315691\n",
            "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 2.302482\n",
            "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 2.304171\n",
            "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 2.305756\n",
            "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 2.302439\n",
            "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 2.312806\n",
            "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 2.342418\n",
            "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 2.350959\n",
            "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 2.314915\n",
            "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 2.286166\n",
            "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 2.318479\n",
            "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 2.295322\n",
            "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 2.297400\n",
            "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 2.353573\n",
            "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 2.310647\n",
            "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 2.298493\n",
            "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 2.300128\n",
            "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 2.302330\n",
            "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 2.324952\n",
            "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 2.311085\n",
            "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 2.324428\n",
            "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 2.343979\n",
            "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 2.298809\n",
            "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 2.276497\n",
            "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 2.354447\n",
            "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 2.300341\n",
            "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 2.325382\n",
            "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 2.296899\n",
            "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 2.301309\n",
            "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 2.314210\n",
            "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 2.300987\n",
            "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 2.292427\n",
            "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 2.307435\n",
            "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 2.310908\n",
            "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 2.339383\n",
            "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 2.281606\n",
            "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 2.316310\n",
            "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 2.312074\n",
            "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 2.297055\n",
            "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 2.298954\n",
            "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 2.317957\n",
            "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 2.319007\n",
            "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 2.320378\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0366, Accuracy: 982/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 2.372184\n",
            "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 2.276463\n",
            "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 2.291947\n",
            "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 2.314780\n",
            "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 2.317983\n",
            "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 2.293610\n",
            "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 2.303629\n",
            "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 2.336600\n",
            "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 2.315366\n",
            "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 2.328019\n",
            "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 2.308945\n",
            "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 2.355966\n",
            "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 2.297335\n",
            "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 2.328279\n",
            "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 2.340247\n",
            "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 2.326643\n",
            "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 2.292743\n",
            "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 2.304531\n",
            "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 2.331987\n",
            "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 2.327393\n",
            "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 2.339522\n",
            "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 2.324095\n",
            "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 2.340901\n",
            "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 2.289411\n",
            "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 2.295776\n",
            "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 2.297894\n",
            "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 2.330732\n",
            "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 2.342220\n",
            "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 2.338217\n",
            "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 2.329433\n",
            "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 2.316099\n",
            "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 2.295703\n",
            "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 2.299563\n",
            "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 2.329540\n",
            "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 2.326477\n",
            "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 2.318180\n",
            "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 2.303493\n",
            "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 2.312061\n",
            "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 2.317299\n",
            "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 2.293147\n",
            "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 2.333367\n",
            "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 2.304595\n",
            "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 2.316889\n",
            "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 2.327708\n",
            "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 2.293869\n",
            "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 2.292150\n",
            "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 2.324965\n",
            "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 2.311279\n",
            "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 2.310793\n",
            "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 2.311064\n",
            "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 2.342818\n",
            "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 2.303855\n",
            "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 2.327777\n",
            "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 2.326741\n",
            "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 2.297211\n",
            "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 2.299721\n",
            "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 2.315443\n",
            "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 2.297300\n",
            "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 2.289041\n",
            "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 2.340444\n",
            "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 2.301565\n",
            "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 2.312865\n",
            "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 2.294049\n",
            "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 2.333207\n",
            "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 2.299160\n",
            "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 2.314758\n",
            "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 2.310118\n",
            "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 2.356845\n",
            "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 2.284894\n",
            "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 2.346664\n",
            "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 2.283211\n",
            "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 2.336288\n",
            "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 2.318009\n",
            "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 2.282233\n",
            "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 2.319895\n",
            "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 2.322391\n",
            "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 2.329405\n",
            "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 2.316112\n",
            "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 2.307539\n",
            "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 2.317077\n",
            "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 2.309553\n",
            "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 2.329869\n",
            "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 2.313522\n",
            "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 2.304583\n",
            "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 2.322986\n",
            "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 2.336679\n",
            "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 2.312241\n",
            "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 2.299822\n",
            "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 2.307646\n",
            "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 2.324960\n",
            "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 2.311704\n",
            "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 2.318747\n",
            "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 2.317831\n",
            "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 2.303905\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0363, Accuracy: 1135/10000 (11%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 2.346128\n",
            "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 2.372885\n",
            "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 2.318563\n",
            "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 2.294800\n",
            "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 2.325208\n",
            "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 2.389865\n",
            "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 2.306061\n",
            "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 2.300126\n",
            "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 2.300565\n",
            "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 2.270803\n",
            "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 2.311509\n",
            "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 2.291026\n",
            "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 2.316619\n",
            "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 2.321932\n",
            "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 2.347649\n",
            "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 2.296067\n",
            "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 2.287175\n",
            "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 2.313931\n",
            "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 2.358207\n",
            "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 2.315662\n",
            "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 2.300918\n",
            "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 2.331770\n",
            "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 2.285737\n",
            "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 2.299902\n",
            "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 2.297491\n",
            "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 2.346059\n",
            "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 2.316464\n",
            "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 2.310753\n",
            "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 2.287668\n",
            "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 2.313081\n",
            "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 2.320412\n",
            "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 2.286111\n",
            "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 2.341313\n",
            "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 2.300170\n",
            "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 2.302468\n",
            "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 2.342363\n",
            "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 2.316889\n",
            "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 2.298981\n",
            "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 2.293200\n",
            "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 2.303916\n",
            "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 2.309362\n",
            "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 2.278888\n",
            "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 2.311285\n",
            "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 2.295317\n",
            "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 2.316307\n",
            "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 2.314220\n",
            "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 2.357439\n",
            "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 2.309051\n",
            "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 2.301093\n",
            "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 2.327265\n",
            "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 2.300499\n",
            "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 2.300132\n",
            "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 2.343585\n",
            "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 2.290439\n",
            "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 2.308728\n",
            "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 2.304154\n",
            "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 2.295244\n",
            "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 2.280798\n",
            "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 2.346096\n",
            "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 2.371621\n",
            "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 2.291263\n",
            "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 2.306862\n",
            "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 2.368039\n",
            "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 2.290196\n",
            "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 2.328473\n",
            "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 2.295129\n",
            "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 2.296274\n",
            "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 2.294157\n",
            "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 2.351382\n",
            "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 2.298078\n",
            "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 2.318585\n",
            "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 2.313576\n",
            "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 2.316047\n",
            "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 2.314442\n",
            "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 2.249714\n",
            "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 2.295235\n",
            "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 2.296465\n",
            "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 2.318571\n",
            "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 2.302902\n",
            "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 2.319642\n",
            "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 2.389786\n",
            "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 2.329627\n",
            "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 2.311058\n",
            "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 2.303992\n",
            "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 2.368865\n",
            "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 2.317252\n",
            "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 2.305580\n",
            "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 2.313694\n",
            "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 2.290256\n",
            "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 2.397652\n",
            "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 2.302794\n",
            "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 2.283034\n",
            "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 2.333110\n",
            "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 2.359491\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0367, Accuracy: 980/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 2.351973\n",
            "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 2.267087\n",
            "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 2.305813\n",
            "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 2.378130\n",
            "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 2.282858\n",
            "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 2.323689\n",
            "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 2.290117\n",
            "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 2.304040\n",
            "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 2.264621\n",
            "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 2.313160\n",
            "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 2.311890\n",
            "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 2.342975\n",
            "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 2.302244\n",
            "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 2.295897\n",
            "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 2.300770\n",
            "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 2.303849\n",
            "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 2.337719\n",
            "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 2.325961\n",
            "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 2.295440\n",
            "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 2.308858\n",
            "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 2.307776\n",
            "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 2.302671\n",
            "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 2.320212\n",
            "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 2.272231\n",
            "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 2.293057\n",
            "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 2.307195\n",
            "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 2.304657\n",
            "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 2.364145\n",
            "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 2.300753\n",
            "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 2.309403\n",
            "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 2.308063\n",
            "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 2.338238\n",
            "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 2.303603\n",
            "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 2.294848\n",
            "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 2.273031\n",
            "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 2.304519\n",
            "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 2.308114\n",
            "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 2.304658\n",
            "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 2.341912\n",
            "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 2.297687\n",
            "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 2.295299\n",
            "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 2.297924\n",
            "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 2.327509\n",
            "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 2.311665\n",
            "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 2.295592\n",
            "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 2.314675\n",
            "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 2.297771\n",
            "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 2.300128\n",
            "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 2.310972\n",
            "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 2.300145\n",
            "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 2.279577\n",
            "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 2.299508\n",
            "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 2.308885\n",
            "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 2.318970\n",
            "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 2.328118\n",
            "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 2.280768\n",
            "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 2.330738\n",
            "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 2.280863\n",
            "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 2.305447\n",
            "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 2.294824\n",
            "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 2.292689\n",
            "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 2.372911\n",
            "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 2.272026\n",
            "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 2.267073\n",
            "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 2.318155\n",
            "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 2.314305\n",
            "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 2.330874\n",
            "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 2.297475\n",
            "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 2.293050\n",
            "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 2.345011\n",
            "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 2.340338\n",
            "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 2.297485\n",
            "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 2.346950\n",
            "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 2.302164\n",
            "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 2.304342\n",
            "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 2.321499\n",
            "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 2.322726\n",
            "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 2.307109\n",
            "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 2.300534\n",
            "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 2.301157\n",
            "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 2.297006\n",
            "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 2.356357\n",
            "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 2.306084\n",
            "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 2.311433\n",
            "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 2.287987\n",
            "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 2.346165\n",
            "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 2.306194\n",
            "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 2.266544\n",
            "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 2.293033\n",
            "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 2.289330\n",
            "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 2.316821\n",
            "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 2.293403\n",
            "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 2.288436\n",
            "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 2.343870\n",
            "Training time: 1m 3s\n",
            "===========================\n",
            "Test set: Average loss: 0.0362, Accuracy: 1028/10000 (10%)\n",
            "Testing time: 1m 7s\n",
            "Total Time: 10m 1s\n",
            "Model was trained on cuda!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-qL-LbdZd6U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}