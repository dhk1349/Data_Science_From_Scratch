{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. ANN\n",
    "## 0.1 모델의 정의\n",
    "\n",
    "## 0.2 모델의 목표\n",
    "\n",
    "## 0.3 사용할 모델\n",
    "\n",
    "## 0.4 모델의 사용 이유\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras import layers \n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PCT 모델\n",
    "<p>PCT를 예측하는 모델이다. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 PCT모델1\n",
    "<p>기본 데이터셋에서 가지고 있는 모든 Column 데이터를 사용해서 PCT를 예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=pd.read_csv(\"PCT\\\\PCT_train_x.csv\")\n",
    "PCT_y_train=pd.read_csv(\"PCT\\\\PCT_train_y.csv\")\n",
    "PCT_x_test=pd.read_csv(\"PCT\\\\PCT_test_x.csv\")\n",
    "PCT_y_test=pd.read_csv(\"PCT\\\\PCT_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 데이터 전처리\n",
    "<p>Training 과 Prediction에서 불필요한 T_ID, YEAR, shift_HEADER_NO를 제거하였다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=PCT_x_train.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "PCT_x_test=PCT_x_test.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "PCT_y_train=PCT_y_train.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "#PCT_y_test=PCT_y_test.drop(columns=[\"T_ID\", \"YEAR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 PCT모델1 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(PCT_x_train.keys())]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 10 == 0: print('')\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 17:50:54.591986 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                3712      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "..........\n",
      "..........\n",
      "..........\n",
      ".....Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "EPOCHS = 100\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "  PCT_x_train, PCT_y_train,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot(), early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 PCT모델1 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 17:53:03.325359 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>PCT</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HH</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.436020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.406186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.538021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.571580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.546638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.451373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OB</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.510216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.482959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SS</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.707297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HH</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.496931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.441289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.478370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.517712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.559464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.480857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.610305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.574359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WO</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.528751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HH</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.502226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.577664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.426085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.541177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OB</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.383414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.528359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.553028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WO</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.561610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HH</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.280141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.471881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.339698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.440740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.513179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.500015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.508969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SS</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.435094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WO</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.462574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HH</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.576774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.604758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.443191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LG</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.534709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.517156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NC</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.526948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OB</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.519766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.424915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.490312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WO</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.545433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       PCT    y_pred\n",
       "0    HH  2016  0.500000  0.436020\n",
       "1    HT  2016  0.458333  0.406186\n",
       "2    KT  2016  0.291667  0.538021\n",
       "3    LG  2016  0.608696  0.571580\n",
       "4    LT  2016  0.500000  0.546638\n",
       "5    NC  2016  0.565217  0.451373\n",
       "6    OB  2016  0.666667  0.510216\n",
       "7    SK  2016  0.458333  0.482959\n",
       "8    SS  2016  0.500000  0.707297\n",
       "9    WO  2016  0.375000  0.545837\n",
       "10   HH  2017  0.434783  0.496931\n",
       "11   HT  2017  0.500000  0.441289\n",
       "12   KT  2017  0.500000  0.484115\n",
       "13   LG  2017  0.434783  0.478370\n",
       "14   LT  2017  0.666667  0.517712\n",
       "15   NC  2017  0.500000  0.559464\n",
       "16   OB  2017  0.583333  0.480857\n",
       "17   SK  2017  0.625000  0.610305\n",
       "18   SS  2017  0.391304  0.574359\n",
       "19   WO  2017  0.347826  0.528751\n",
       "20   HH  2018  0.500000  0.564588\n",
       "21   HT  2018  0.541667  0.502226\n",
       "22   KT  2018  0.391304  0.421338\n",
       "23   LG  2018  0.416667  0.577664\n",
       "24   LT  2018  0.666667  0.426085\n",
       "25   NC  2018  0.416667  0.541177\n",
       "26   OB  2018  0.625000  0.383414\n",
       "27   SK  2018  0.458333  0.528359\n",
       "28   SS  2018  0.521739  0.553028\n",
       "29   WO  2018  0.541667  0.561610\n",
       "30   HH  2019  0.583333  0.280141\n",
       "31   HT  2019  0.500000  0.552239\n",
       "32   KT  2019  0.541667  0.471881\n",
       "33   LG  2019  0.541667  0.339698\n",
       "34   LT  2019  0.208333  0.440740\n",
       "35   NC  2019  0.565217  0.513179\n",
       "36   OB  2019  0.652174  0.500015\n",
       "37   SK  2019  0.375000  0.508969\n",
       "38   SS  2019  0.416667  0.435094\n",
       "39   WO  2019  0.666667  0.462574\n",
       "40   HH  2020  0.291667  0.576774\n",
       "41   HT  2020  0.500000  0.604758\n",
       "42   KT  2020  0.608696  0.443191\n",
       "43   LG  2020  0.391304  0.534709\n",
       "44   LT  2020  0.458333  0.517156\n",
       "45   NC  2020  0.681818  0.526948\n",
       "46   OB  2020  0.583333  0.519766\n",
       "47   SK  2020  0.375000  0.424915\n",
       "48   SS  2020  0.625000  0.490312\n",
       "49   WO  2020  0.541667  0.545433"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(PCT_x_test)\n",
    "PCT_y_test['y_pred']=y_pred\n",
    "PCT_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01872916238939003"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(PCT_y_test['PCT'], y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11193741650213836"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(PCT_y_test['PCT'], y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "success=0\n",
    "fail=0\n",
    "for idx in PCT_y_test.index:\n",
    "    if(PCT_y_test['PCT'][idx] <PCT_y_test['y_pred'][idx]+mae and PCT_y_test['PCT'][idx] >PCT_y_test['y_pred'][idx]-mae ):\n",
    "        success+=1\n",
    "    else:\n",
    "        fail+=1\n",
    "print(success)\n",
    "print(fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PCT모델2\n",
    "<p>PCT와 상관관계가 일정 수준 이상이 Column으로만 PCT예측.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=pd.read_csv(\"PCT\\\\PCT_train_x.csv\")\n",
    "PCT_y_train=pd.read_csv(\"PCT\\\\PCT_train_y.csv\")\n",
    "PCT_x_test=pd.read_csv(\"PCT\\\\PCT_test_x.csv\")\n",
    "PCT_y_test=pd.read_csv(\"PCT\\\\PCT_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 데이터 전처리\n",
    "<p>Training 과 Prediction에서 불필요한 T_ID, YEAR, shift_HEADER_NO를 제거하였다. <br>\n",
    "데이터셋에서 타겟 데이터인 PCT와 상관관계가 0.15보다 낮은 column은 제거 하였으며, 음의 상관관계를 갖는 column은 -1을 곱하였였다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift_ERA</th>\n",
       "      <th>shift_FIP</th>\n",
       "      <th>shift_HR_9</th>\n",
       "      <th>shift_H_9</th>\n",
       "      <th>shift_LOB</th>\n",
       "      <th>shift_P2_WHIP_RT</th>\n",
       "      <th>shift_PCT</th>\n",
       "      <th>shift_P_HRA_RT</th>\n",
       "      <th>shift_TA</th>\n",
       "      <th>shift_WHIP</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_vs_FIP</th>\n",
       "      <th>shift_vs_H_9</th>\n",
       "      <th>shift_vs_P2_WHIP_RT</th>\n",
       "      <th>shift_vs_P_WHIP_RT</th>\n",
       "      <th>shift_vs_WHIP</th>\n",
       "      <th>shift_vs_oAVG</th>\n",
       "      <th>shift_vs_oOBP</th>\n",
       "      <th>shift_vs_oOPS</th>\n",
       "      <th>shift_vs_oSLG</th>\n",
       "      <th>shift_wOBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.412500</td>\n",
       "      <td>-1.645312</td>\n",
       "      <td>-1.307813</td>\n",
       "      <td>-11.053125</td>\n",
       "      <td>0.616863</td>\n",
       "      <td>-2.183124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.484545</td>\n",
       "      <td>0.743631</td>\n",
       "      <td>-1.654688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.183099</td>\n",
       "      <td>10.563380</td>\n",
       "      <td>2.508846</td>\n",
       "      <td>1.666098</td>\n",
       "      <td>1.525822</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.771179</td>\n",
       "      <td>0.429074</td>\n",
       "      <td>0.388722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.957746</td>\n",
       "      <td>-1.211268</td>\n",
       "      <td>-0.929577</td>\n",
       "      <td>-11.028169</td>\n",
       "      <td>0.643105</td>\n",
       "      <td>-1.888173</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.788382</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>-1.713615</td>\n",
       "      <td>...</td>\n",
       "      <td>2.127358</td>\n",
       "      <td>10.570755</td>\n",
       "      <td>1.869886</td>\n",
       "      <td>1.359285</td>\n",
       "      <td>1.518868</td>\n",
       "      <td>0.297136</td>\n",
       "      <td>0.340741</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.484487</td>\n",
       "      <td>0.408927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.736422</td>\n",
       "      <td>-1.207668</td>\n",
       "      <td>-1.078275</td>\n",
       "      <td>-11.257188</td>\n",
       "      <td>0.644654</td>\n",
       "      <td>-1.969625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.433328</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>-1.638978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>9.960754</td>\n",
       "      <td>1.703920</td>\n",
       "      <td>1.368628</td>\n",
       "      <td>1.469388</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.336570</td>\n",
       "      <td>0.727718</td>\n",
       "      <td>0.391148</td>\n",
       "      <td>0.366139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.400000</td>\n",
       "      <td>-1.052381</td>\n",
       "      <td>-0.771429</td>\n",
       "      <td>-10.114286</td>\n",
       "      <td>0.638767</td>\n",
       "      <td>-2.408081</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>6.283159</td>\n",
       "      <td>0.729642</td>\n",
       "      <td>-1.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793978</td>\n",
       "      <td>10.483360</td>\n",
       "      <td>2.138345</td>\n",
       "      <td>1.341337</td>\n",
       "      <td>1.511886</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.343784</td>\n",
       "      <td>0.769913</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.377988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.314286</td>\n",
       "      <td>-1.695238</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>-10.757143</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-2.204590</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.280412</td>\n",
       "      <td>0.741214</td>\n",
       "      <td>-1.580952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064669</td>\n",
       "      <td>8.730284</td>\n",
       "      <td>1.711120</td>\n",
       "      <td>1.627467</td>\n",
       "      <td>1.537855</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.345745</td>\n",
       "      <td>0.719938</td>\n",
       "      <td>0.374194</td>\n",
       "      <td>0.389660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shift_ERA  shift_FIP  shift_HR_9  shift_H_9  shift_LOB  shift_P2_WHIP_RT  \\\n",
       "0  -6.412500  -1.645312   -1.307813 -11.053125   0.616863         -2.183124   \n",
       "1  -5.957746  -1.211268   -0.929577 -11.028169   0.643105         -1.888173   \n",
       "2  -5.736422  -1.207668   -1.078275 -11.257188   0.644654         -1.969625   \n",
       "3  -5.400000  -1.052381   -0.771429 -10.114286   0.638767         -2.408081   \n",
       "4  -5.314286  -1.695238   -1.285714 -10.757143   0.700000         -2.204590   \n",
       "\n",
       "   shift_PCT  shift_P_HRA_RT  shift_TA  shift_WHIP  ...  shift_vs_FIP  \\\n",
       "0   0.500000        7.484545  0.743631   -1.654688  ...      1.183099   \n",
       "1   0.500000        5.788382  0.824561   -1.713615  ...      2.127358   \n",
       "2   0.333333        5.433328  0.685484   -1.638978  ...      0.612245   \n",
       "3   0.583333        6.283159  0.729642   -1.533333  ...      0.793978   \n",
       "4   0.375000        5.280412  0.741214   -1.580952  ...      1.064669   \n",
       "\n",
       "   shift_vs_H_9  shift_vs_P2_WHIP_RT  shift_vs_P_WHIP_RT  shift_vs_WHIP  \\\n",
       "0     10.563380             2.508846            1.666098       1.525822   \n",
       "1     10.570755             1.869886            1.359285       1.518868   \n",
       "2      9.960754             1.703920            1.368628       1.469388   \n",
       "3     10.483360             2.138345            1.341337       1.511886   \n",
       "4      8.730284             1.711120            1.627467       1.537855   \n",
       "\n",
       "   shift_vs_oAVG  shift_vs_oOBP  shift_vs_oOPS  shift_vs_oSLG  shift_wOBA  \n",
       "0       0.293083       0.342105       0.771179       0.429074    0.388722  \n",
       "1       0.297136       0.340741       0.825228       0.484487    0.408927  \n",
       "2       0.281100       0.336570       0.727718       0.391148    0.366139  \n",
       "3       0.299145       0.343784       0.769913       0.426129    0.377988  \n",
       "4       0.264516       0.345745       0.719938       0.374194    0.389660  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCT_x_train=PCT_x_train.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "PCT_x_test=PCT_x_test.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "\n",
    "PCT_x_train['target']=PCT_y_train['PCT']\n",
    "\n",
    "corr_x_train=PCT_x_train.corr()\n",
    "\n",
    "sign=[0 if abs(e)<0.15 else np.sign(e) for e in corr_x_train['target'].to_list()]\n",
    "sign=sign[:-1]\n",
    "\n",
    "remove_idx=[idx for idx,i in enumerate(sign) if (i==0)]\n",
    "\n",
    "PCT_x_train=PCT_x_train.drop(columns=['target'])\n",
    "PCT_x_train=PCT_x_train.drop(columns=[i for idx,i in enumerate(PCT_x_train.columns) if idx in remove_idx])\n",
    "PCT_x_test=PCT_x_test.drop(columns=[i for idx,i in enumerate(PCT_x_test.columns) if idx in remove_idx])\n",
    "sign=[i for i in sign if i!=0]\n",
    "PCT_x_train=PCT_x_train*sign\n",
    "PCT_x_test=PCT_x_test*sign\n",
    "PCT_x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift_ERA</th>\n",
       "      <th>shift_FIP</th>\n",
       "      <th>shift_HR_9</th>\n",
       "      <th>shift_H_9</th>\n",
       "      <th>shift_LOB</th>\n",
       "      <th>shift_P2_WHIP_RT</th>\n",
       "      <th>shift_PCT</th>\n",
       "      <th>shift_P_HRA_RT</th>\n",
       "      <th>shift_TA</th>\n",
       "      <th>shift_WHIP</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_vs_FIP</th>\n",
       "      <th>shift_vs_H_9</th>\n",
       "      <th>shift_vs_P2_WHIP_RT</th>\n",
       "      <th>shift_vs_P_WHIP_RT</th>\n",
       "      <th>shift_vs_WHIP</th>\n",
       "      <th>shift_vs_oAVG</th>\n",
       "      <th>shift_vs_oOBP</th>\n",
       "      <th>shift_vs_oOPS</th>\n",
       "      <th>shift_vs_oSLG</th>\n",
       "      <th>shift_wOBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.358462</td>\n",
       "      <td>-0.918462</td>\n",
       "      <td>-0.789231</td>\n",
       "      <td>-10.509231</td>\n",
       "      <td>0.649666</td>\n",
       "      <td>-1.958307</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.206516</td>\n",
       "      <td>0.702028</td>\n",
       "      <td>-1.583077</td>\n",
       "      <td>...</td>\n",
       "      <td>1.297546</td>\n",
       "      <td>8.696319</td>\n",
       "      <td>1.544842</td>\n",
       "      <td>1.419553</td>\n",
       "      <td>1.417178</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.717523</td>\n",
       "      <td>0.391941</td>\n",
       "      <td>0.366735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.715611</td>\n",
       "      <td>-0.927357</td>\n",
       "      <td>-0.500773</td>\n",
       "      <td>-9.431221</td>\n",
       "      <td>0.678705</td>\n",
       "      <td>-1.786932</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>6.709970</td>\n",
       "      <td>0.739269</td>\n",
       "      <td>-1.506955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730354</td>\n",
       "      <td>10.151002</td>\n",
       "      <td>1.626840</td>\n",
       "      <td>1.796928</td>\n",
       "      <td>1.511556</td>\n",
       "      <td>0.293976</td>\n",
       "      <td>0.345301</td>\n",
       "      <td>0.760964</td>\n",
       "      <td>0.415663</td>\n",
       "      <td>0.383094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.584759</td>\n",
       "      <td>-1.996890</td>\n",
       "      <td>-1.259720</td>\n",
       "      <td>-10.371695</td>\n",
       "      <td>0.655063</td>\n",
       "      <td>-2.005702</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.989481</td>\n",
       "      <td>0.768371</td>\n",
       "      <td>-1.553655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795349</td>\n",
       "      <td>11.176744</td>\n",
       "      <td>1.630535</td>\n",
       "      <td>1.620795</td>\n",
       "      <td>1.609302</td>\n",
       "      <td>0.310827</td>\n",
       "      <td>0.356334</td>\n",
       "      <td>0.781246</td>\n",
       "      <td>0.424913</td>\n",
       "      <td>0.393585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.551402</td>\n",
       "      <td>-1.827103</td>\n",
       "      <td>-1.093458</td>\n",
       "      <td>-10.219626</td>\n",
       "      <td>0.637136</td>\n",
       "      <td>-2.142594</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>6.976934</td>\n",
       "      <td>0.816746</td>\n",
       "      <td>-1.588785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435185</td>\n",
       "      <td>10.708333</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>1.930443</td>\n",
       "      <td>1.643519</td>\n",
       "      <td>0.300585</td>\n",
       "      <td>0.360772</td>\n",
       "      <td>0.808726</td>\n",
       "      <td>0.447953</td>\n",
       "      <td>0.409351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.492236</td>\n",
       "      <td>-0.996894</td>\n",
       "      <td>-0.796584</td>\n",
       "      <td>-10.858696</td>\n",
       "      <td>0.648038</td>\n",
       "      <td>-1.967236</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.257798</td>\n",
       "      <td>0.707087</td>\n",
       "      <td>-1.625776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304954</td>\n",
       "      <td>8.818885</td>\n",
       "      <td>1.560868</td>\n",
       "      <td>1.446338</td>\n",
       "      <td>1.430341</td>\n",
       "      <td>0.258578</td>\n",
       "      <td>0.328009</td>\n",
       "      <td>0.723842</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.368900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shift_ERA  shift_FIP  shift_HR_9  shift_H_9  shift_LOB  shift_P2_WHIP_RT  \\\n",
       "0  -5.358462  -0.918462   -0.789231 -10.509231   0.649666         -1.958307   \n",
       "1  -4.715611  -0.927357   -0.500773  -9.431221   0.678705         -1.786932   \n",
       "2  -5.584759  -1.996890   -1.259720 -10.371695   0.655063         -2.005702   \n",
       "3  -5.551402  -1.827103   -1.093458 -10.219626   0.637136         -2.142594   \n",
       "4  -5.492236  -0.996894   -0.796584 -10.858696   0.648038         -1.967236   \n",
       "\n",
       "   shift_PCT  shift_P_HRA_RT  shift_TA  shift_WHIP  ...  shift_vs_FIP  \\\n",
       "0   0.500000        5.206516  0.702028   -1.583077  ...      1.297546   \n",
       "1   0.478261        6.709970  0.739269   -1.506955  ...      0.730354   \n",
       "2   0.375000        5.989481  0.768371   -1.553655  ...      0.795349   \n",
       "3   0.458333        6.976934  0.816746   -1.588785  ...      1.435185   \n",
       "4   0.500000        5.257798  0.707087   -1.625776  ...      1.304954   \n",
       "\n",
       "   shift_vs_H_9  shift_vs_P2_WHIP_RT  shift_vs_P_WHIP_RT  shift_vs_WHIP  \\\n",
       "0      8.696319             1.544842            1.419553       1.417178   \n",
       "1     10.151002             1.626840            1.796928       1.511556   \n",
       "2     11.176744             1.630535            1.620795       1.609302   \n",
       "3     10.708333             2.127660            1.930443       1.643519   \n",
       "4      8.818885             1.560868            1.446338       1.430341   \n",
       "\n",
       "   shift_vs_oAVG  shift_vs_oOBP  shift_vs_oOPS  shift_vs_oSLG  shift_wOBA  \n",
       "0       0.256410       0.325581       0.717523       0.391941    0.366735  \n",
       "1       0.293976       0.345301       0.760964       0.415663    0.383094  \n",
       "2       0.310827       0.356334       0.781246       0.424913    0.393585  \n",
       "3       0.300585       0.360772       0.808726       0.447953    0.409351  \n",
       "4       0.258578       0.328009       0.723842       0.395833    0.368900  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCT_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['T_ID' 'YEAR'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-3397e41ed22e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPCT_y_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCT_y_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T_ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"YEAR\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['T_ID' 'YEAR'] not found in axis\""
     ]
    }
   ],
   "source": [
    "PCT_y_train=PCT_y_train.drop(columns=[\"T_ID\", \"YEAR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 PCT모델2 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(PCT_x_train.keys())]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:21:28.159342 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 64)                1856      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,305\n",
      "Trainable params: 10,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      ".Epoch 00061: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model2()\n",
    "model2.summary()\n",
    "\n",
    "history = model2.fit(\n",
    "  PCT_x_train, PCT_y_train,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot(), early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 PCT모델2 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:22:11.529724 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>PCT</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HH</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.474532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.470814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.549657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.486322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.555469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OB</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.704482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.496224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SS</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.575733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HH</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.488437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.435064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.491170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.392330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.475583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.474867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.548345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.529226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.529198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WO</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.509369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HH</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.351126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.564386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.449318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.482198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.443066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OB</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.406625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.362043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.467096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WO</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.524937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HH</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.313088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.331779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.507239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.236286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.375496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.496664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.488265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.480600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SS</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.535402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WO</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.493422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HH</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.560086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.432217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LG</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.585111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.447832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NC</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.531296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OB</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.546958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.406228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.544299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WO</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.505516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       PCT    y_pred\n",
       "0    HH  2016  0.500000  0.483778\n",
       "1    HT  2016  0.458333  0.474532\n",
       "2    KT  2016  0.291667  0.470814\n",
       "3    LG  2016  0.608696  0.549657\n",
       "4    LT  2016  0.500000  0.486322\n",
       "5    NC  2016  0.565217  0.555469\n",
       "6    OB  2016  0.666667  0.704482\n",
       "7    SK  2016  0.458333  0.496224\n",
       "8    SS  2016  0.500000  0.444744\n",
       "9    WO  2016  0.375000  0.575733\n",
       "10   HH  2017  0.434783  0.488437\n",
       "11   HT  2017  0.500000  0.435064\n",
       "12   KT  2017  0.500000  0.491170\n",
       "13   LG  2017  0.434783  0.392330\n",
       "14   LT  2017  0.666667  0.475583\n",
       "15   NC  2017  0.500000  0.474867\n",
       "16   OB  2017  0.583333  0.548345\n",
       "17   SK  2017  0.625000  0.529226\n",
       "18   SS  2017  0.391304  0.529198\n",
       "19   WO  2017  0.347826  0.509369\n",
       "20   HH  2018  0.500000  0.351126\n",
       "21   HT  2018  0.541667  0.564386\n",
       "22   KT  2018  0.391304  0.449318\n",
       "23   LG  2018  0.416667  0.482198\n",
       "24   LT  2018  0.666667  0.451098\n",
       "25   NC  2018  0.416667  0.443066\n",
       "26   OB  2018  0.625000  0.406625\n",
       "27   SK  2018  0.458333  0.362043\n",
       "28   SS  2018  0.521739  0.467096\n",
       "29   WO  2018  0.541667  0.524937\n",
       "30   HH  2019  0.583333  0.313088\n",
       "31   HT  2019  0.500000  0.331779\n",
       "32   KT  2019  0.541667  0.507239\n",
       "33   LG  2019  0.541667  0.236286\n",
       "34   LT  2019  0.208333  0.375496\n",
       "35   NC  2019  0.565217  0.496664\n",
       "36   OB  2019  0.652174  0.488265\n",
       "37   SK  2019  0.375000  0.480600\n",
       "38   SS  2019  0.416667  0.535402\n",
       "39   WO  2019  0.666667  0.493422\n",
       "40   HH  2020  0.291667  0.560086\n",
       "41   HT  2020  0.500000  0.520713\n",
       "42   KT  2020  0.608696  0.432217\n",
       "43   LG  2020  0.391304  0.585111\n",
       "44   LT  2020  0.458333  0.447832\n",
       "45   NC  2020  0.681818  0.531296\n",
       "46   OB  2020  0.583333  0.546958\n",
       "47   SK  2020  0.375000  0.406228\n",
       "48   SS  2020  0.625000  0.544299\n",
       "49   WO  2020  0.541667  0.505516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(PCT_x_test)\n",
    "PCT_y_test['y_pred']=y_pred\n",
    "PCT_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01613147939911719"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(PCT_y_test['PCT'], y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0989107538172693"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(PCT_y_test['PCT'], y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "success=0\n",
    "fail=0\n",
    "for idx in PCT_y_test.index:\n",
    "    if(PCT_y_test['PCT'][idx] <PCT_y_test['y_pred'][idx]+mae and PCT_y_test['PCT'][idx] >PCT_y_test['y_pred'][idx]-mae ):\n",
    "        success+=1\n",
    "    else:\n",
    "        fail+=1\n",
    "print(success)\n",
    "print(fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 PCT모델3\n",
    "<p>시즌과 팀 별로 개별적인 모델을 만들어서 트레이닝한다. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=pd.read_csv(\"PCT\\\\PCT_train_x.csv\")\n",
    "PCT_y_train=pd.read_csv(\"PCT\\\\PCT_train_y.csv\")\n",
    "PCT_x_test=pd.read_csv(\"PCT\\\\PCT_test_x.csv\")\n",
    "PCT_y_test=pd.read_csv(\"PCT\\\\PCT_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 데이터 전처리\n",
    "<p>별도의 전처리 없이 데이터셋으로부터 시즌 정보와 팀정보만 가져온다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = list(PCT_x_train.T_ID.unique())\n",
    "year = list(PCT_y_train.YEAR.unique())\n",
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 PCT모델3 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:34.102024 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 7470366258.3327 - mae: 37465.1484\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 1440346.6295 - mae: 709.6336\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 489557.9145 - mae: 580.7958\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 247423.5166 - mae: 393.4652\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 125432.6324 - mae: 273.7141\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 88588.4341 - mae: 238.5541\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 132217.3048 - mae: 286.1334\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 106000.2937 - mae: 261.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:43.048894 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "2016HH =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:43.413918 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 1078124122.9738 - mae: 17221.4395\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 226190.4591 - mae: 351.6959\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 8533.4536 - mae: 74.2389\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/sample - loss: 8945.2400 - mae: 75.7082\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 9413.3114 - mae: 78.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:49.086744 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "2016NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:49.344056 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 3994342187.0335 - mae: 34337.2969\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 11782679.5896 - mae: 1883.4171\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 27658.7636 - mae: 131.0122\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 13751.4909 - mae: 92.8837\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 15892.3355 - mae: 100.2056\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 23474.4264 - mae: 126.8318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:57.260394 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "2016HT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:32:57.609459 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1046310652.4100 - mae: 15594.1885s - loss: 1556655114.3463 - m\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 70246.4986 - mae: 185.72040s - loss:\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 8464.3377 - mae: 75.8947\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 5431.1717 - mae: 58.5452\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4946.4590 - mae: 55.5610\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 6911.5282 - mae: 67.7162\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4868.8008 - mae: 55.37400s - loss: 5234.3070 - ma\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 6741.7788 - mae: 67.8879\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 3623.1985 - mae: 48.4266\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 3754.0768 - mae: 50.1902\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4479.3325 - mae: 53.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:13.477240 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "2016SK =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:13.884153 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 2519507611.9771 - mae: 25376.7246\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1673035.7685 - mae: 1090.1167s - l\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 336932.9170 - mae: 490.7957\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 226441.3197 - mae: 383.0509\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 170998.9891 - mae: 321.5241\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 123098.5717 - mae: 283.6466\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 242641.2311 - mae: 396.3140\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 160182.2694 - mae: 301.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:27.801925 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "2016KT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:28.505047 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 37ms/sample - loss: 1351417316.3287 - mae: 16802.3125\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 3s 36ms/sample - loss: 107991.2433 - mae: 238.9135s - loss: 124686.5254 - mae\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 3s 38ms/sample - loss: 1897.7587 - mae: 32.0072\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 1212.5395 - mae: 27.99040s - loss: 1229.1946 - mae: 28.328\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 3s 39ms/sample - loss: 4056.7434 - mae: 51.7814\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 3s 36ms/sample - loss: 9683.2587 - mae: 78.40911s - loss: 3805.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:45.158658 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "2016WO =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:33:46.211842 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 3872154580.9637 - mae: 38695.7383\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 4177244.5813 - mae: 1568.5369\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 738341.3157 - mae: 754.4222\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 302562.2651 - mae: 484.4166\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 148963.9133 - mae: 316.8060\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 105569.0059 - mae: 253.9622\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 83108.0333 - mae: 222.8619\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 56215.7971 - mae: 179.30010s - loss: 45602.2037 - mae: 155 - ETA: 0s - loss: 56637.3309 - mae: 179.556\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 45245.6837 - mae: 162.63090s - loss: 46308.4047 - mae: 165.96 - ETA: 0s - loss: 44602.2978 - mae: 161.6\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 48247.1819 - mae: 171.4160\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 33734.4886 - mae: 143.8591\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 22912.6567 - mae: 117.8001\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 21231.6672 - mae: 110.9414\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 12849.7177 - mae: 88.4989\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 14027.9100 - mae: 92.4987\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 10861.4055 - mae: 85.5908\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 7096.9307 - mae: 65.36570s - loss: 7068.1698 - mae: 65.69\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 7330.1778 - mae: 66.9895\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 5800.6297 - mae: 58.72260s - loss: 7272.6319 -\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 5640.3886 - mae: 62.41530s - loss: 6148.6\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 4728.6802 - mae: 57.4374\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 6471.6567 - mae: 60.1638\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 6651.9254 - mae: 65.4137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:20.528402 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: early stopping\n",
      "2016LT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:20.924342 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1238898367.8838 - mae: 17065.1562s - loss: 3\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 50634.2467 - mae: 150.2957\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 428.3021 - mae: 17.2514\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 394.0116 - mae: 15.4783\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 163.8397 - mae: 10.5461\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 119.7109 - mae: 8.7767\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 60.3104 - mae: 6.3476\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 30.7609 - mae: 4.8201s - loss: 3\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 22.3518 - mae: 3.9263\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 16.7674 - mae: 3.4342s -\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 15.1248 - mae: 3.2588\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 11.3693 - mae: 2.8368\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 12.8029 - mae: 3.0050\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 10.2753 - mae: 2.7136\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 9.9329 - mae: 2.72490s - loss: 10.0387 - mae: 2.73 - ETA: 0s - loss: 10.0472 - mae: 2.\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 10.8360 - mae: 2.5979\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 14.5662 - mae: 3.2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:42.900561 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "2016SS =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:43.287524 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1863888838.7965 - mae: 22753.0977\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 269074.2680 - mae: 368.7704\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 7619.0594 - mae: 69.8670\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1677.4129 - mae: 33.89051s - loss: 2587.178\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 360.2981 - mae: 15.5846\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 186.1058 - mae: 10.7466\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 161.5584 - mae: 10.4359\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 191.4092 - mae: 11.5985\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 188.3734 - mae: 11.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:56.180041 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "2016OB =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:34:56.541075 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1143547456.5247 - mae: 18933.7559\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 10688979.7337 - mae: 1839.4821\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 49020.9591 - mae: 182.5799\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 24912.6785 - mae: 131.32061s - loss: 25862.9006 - mae: 145. - ETA: 1s - loss: 26864.9\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 19258.1351 - mae: 114.17510s - loss: 20351.3257 - ma\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 24034.2942 - mae: 122.6119\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 9682.1174 - mae: 74.7739\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 30ms/sample - loss: 7030.9684 - mae: 68.8457\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 5560.7700 - mae: 61.6397\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3804.7847 - mae: 48.2457\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 3000.9849 - mae: 44.00520s - loss: 3063.7802 - mae: 43\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1641.9340 - mae: 32.6747\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 2s 31ms/sample - loss: 1447.4030 - mae: 31.0656\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 714.7464 - mae: 20.9175\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 815.2520 - mae: 22.2175\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 459.3691 - mae: 15.9819s - loss: 450.9601 - mae:\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 2s 32ms/sample - loss: 362.6574 - mae: 14.9203\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 222.7994 - mae: 11.2592\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 191.9398 - mae: 10.9555\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 307.6598 - mae: 14.3546\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 142.9088 - mae: 9.05610s - loss: 152.7087 - mae:\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 213.4020 - mae: 12.1684\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 172.1487 - mae: 10.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:35:37.769796 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: early stopping\n",
      "2017LG =======================================\n",
      "Model: \"sequential\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:35:38.104899 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 922012182.9821 - mae: 16944.8555\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 1462092.9488 - mae: 729.6450\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 35225.7430 - mae: 160.7151\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 10166.7850 - mae: 80.1583\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5293.6228 - mae: 60.0956\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 4754.5737 - mae: 59.07920s - loss: 4804.4099 - mae: 59. - ETA: 0s - loss: 4632.3191 - mae: 58.662\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4065.8025 - mae: 54.8000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 3187.8676 - mae: 48.4308\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2907.9963 - mae: 45.9234\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2241.8559 - mae: 39.1251\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1896.7878 - mae: 36.9624\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1753.1814 - mae: 36.3960\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1410.4013 - mae: 31.2439\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1073.6892 - mae: 26.8643\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 869.0065 - mae: 24.8239\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 661.4467 - mae: 22.2945\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 577.1255 - mae: 20.1032s - loss: 613.9765 - mae: 2\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 447.1524 - mae: 18.1086s - loss: 454.5064 - ma\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 255.4609 - mae: 13.6984\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 242.8977 - mae: 13.3660\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 169.9018 - mae: 10.8456s - loss: 162.9383 - mae: - ETA: 0s - loss: 171.6216 - mae:\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 111.5372 - mae: 8.6515\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 68.9636 - mae: 6.9239\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 62.2513 - mae: 6.7731\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 28.4314 - mae: 4.5598s\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 27.4732 - mae: 4.3876\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 16.4714 - mae: 3.4429\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 12.1224 - mae: 3.0365\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 8.2315 - mae: 2.3261 0s - loss: 9.5566 - mae: \n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5.5052 - mae: 1.8996\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 2.5127 - mae: 1.2316\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 2.1174 - mae: 1.1542\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1.3917 - mae: 0.93400s - loss: 1.4699 - mae: 0.961 - ETA: 0s - loss: 1.5030 - mae:\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 1.1467 - mae: 0.8242\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1.4738 - mae: 1.0164\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1.3411 - mae: 0.8902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:36:24.866822 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: early stopping\n",
      "2017HH =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:36:25.200929 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2458066543.0138 - mae: 25309.6211\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 268175.6119 - mae: 403.3944\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 104929.1149 - mae: 278.8760\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 67545.2094 - mae: 213.6927\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 58607.5886 - mae: 203.23520s - loss: 63497.6049 - mae: \n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 47220.7740 - mae: 181.1757\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 39935.7000 - mae: 166.8623\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 21446.1584 - mae: 121.1554\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 20165.6507 - mae: 124.19030s - loss: 20370.3735 - mae: 124.892\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 18703.6802 - mae: 111.1710\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 12536.2853 - mae: 94.3378\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 13337.1696 - mae: 95.1710\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 2s 32ms/sample - loss: 12272.9577 - mae: 92.0270\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 12540.3903 - mae: 86.1095\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 9046.2999 - mae: 80.3296\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 7509.7199 - mae: 74.0544\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 7444.4694 - mae: 70.2848\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 5825.7549 - mae: 65.4351\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 4874.1624 - mae: 59.8611\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 2s 30ms/sample - loss: 5090.4345 - mae: 57.36650s - loss: 5340.6500 - mae: 58.\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 33ms/sample - loss: 5124.3000 - mae: 58.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:36:59.278774 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n",
      "2017NC =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:00.464604 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 31ms/sample - loss: 2826507491.7808 - mae: 25476.3516s - loss: 4467794178.27\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1202581.7659 - mae: 808.4093\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 97959.7249 - mae: 232.46770s - loss: 100777.7324 - mae: 236\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 30531.1893 - mae: 143.1820\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 20653.7918 - mae: 113.43101s - loss: 22191.7567\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 19001.8572 - mae: 109.4455\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 17123.8513 - mae: 105.0290\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 21201.6790 - mae: 116.40221s - loss: 27847.0\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 11558.5474 - mae: 88.1238\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 21057.6613 - mae: 123.6999\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 9247.7672 - mae: 79.2499\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 9729.5124 - mae: 81.9628\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 13991.3313 - mae: 100.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:21.929189 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "2017HT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:22.436830 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 7285530796.7541 - mae: 50395.7422\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 7245388.5463 - mae: 1875.4069\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 585979.4549 - mae: 607.2302\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 943759.4305 - mae: 792.5370\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 163371.0935 - mae: 316.5012\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 74010.5300 - mae: 208.7479\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 49361.3963 - mae: 181.0600\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 49048.7817 - mae: 178.1384\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 106651.0599 - mae: 256.5738\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 170130.1591 - mae: 330.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:35.875884 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "2017SK =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:36.696688 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 857813450.4075 - mae: 13941.1494\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 34387.4399 - mae: 134.0613\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2205.5081 - mae: 34.6297\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 211.1107 - mae: 11.6362\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 133.1900 - mae: 9.9222\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 196.6024 - mae: 11.0550\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 156.0364 - mae: 10.5044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:46.066625 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n",
      "2017KT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:37:46.359841 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 2581949218.3117 - mae: 32141.0645\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1810953600.9814 - mae: 22836.9609\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1586180.9285 - mae: 790.8113\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 53823.0377 - mae: 193.4390\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 99439.5300 - mae: 260.4335\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 42538.8919 - mae: 167.2618\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 38485.2829 - mae: 149.6398\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 29622.2553 - mae: 138.8582\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 22112.8649 - mae: 120.2778\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 54703.4776 - mae: 192.2503\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 13147.6464 - mae: 95.3880\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 15250.6774 - mae: 102.61481s - los\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 17545.2841 - mae: 102.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:03.678517 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "2017WO =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:04.079447 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 3624297741.5073 - mae: 28417.8164s - loss: 4559101400.0242 - mae: \n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 483871.8134 - mae: 517.9531\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 158420.4808 - mae: 323.3008\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 145366.6536 - mae: 292.3432\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 60497.3379 - mae: 203.8901\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 26621.4963 - mae: 133.41010s - loss: 25457.8458 - mae: 124.753 - ETA: 0s - loss: 25692.8446 - mae: 126.539 - ETA: 0s - loss: 27444.9992 - mae:\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 29990.2515 - mae: 148.5672\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 25819.5522 - mae: 129.3500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 27011.0373 - mae: 131.2649\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 23915.9120 - mae: 130.5273\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 22698.6019 - mae: 124.2361\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 16441.9099 - mae: 105.6833\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 21449.5564 - mae: 119.62561s - lo\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 31ms/sample - loss: 31355.0864 - mae: 145.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:29.427644 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "2017LT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:30.185615 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 984583182.8711 - mae: 15418.83890s - loss: 146508697\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 99488.9211 - mae: 239.7784\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 30ms/sample - loss: 71067.0435 - mae: 219.1942\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 90936.3270 - mae: 240.9887\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 117565.8643 - mae: 291.6568s - loss: 166849.1178 - mae: 356. - ETA: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:40.590785 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "2017SS =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:41.100422 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 7124709644.6879 - mae: 39443.6758\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3355244.1860 - mae: 1324.3020\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 700701.2070 - mae: 705.9452\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 343129.0675 - mae: 470.7382\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 383056.3581 - mae: 510.5584\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 181653.7566 - mae: 340.7345\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 76272.5990 - mae: 220.5403\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 54547.4181 - mae: 188.8723\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 138708.6391 - mae: 294.0116\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 82379.7761 - mae: 220.39470s - loss: 112473.7983 - mae: 277.96 - ETA: 0s - loss: 105890.7739 - mae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:55.180760 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "2017OB =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:38:55.505889 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1553968285.5760 - mae: 21538.7402\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 110950.2811 - mae: 258.2705s - loss: 113099.3503 - mae: 260.76\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 10191.5670 - mae: 85.3768\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 3454.1013 - mae: 47.9365\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2309.0534 - mae: 38.0510\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 2292.4664 - mae: 37.8020\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 2818.6020 - mae: 40.82040s - loss: 2002.2098 - ma\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 2024.9736 - mae: 35.3084\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 2101.9962 - mae: 36.1206\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1966.8523 - mae: 35.5824\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1799.7559 - mae: 34.4428\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1492.9595 - mae: 30.4311\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1473.3474 - mae: 30.66950s - loss: 1461.7237 - mae: 3\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1536.2309 - mae: 31.1967\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1458.9877 - mae: 31.1352\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1605.7996 - mae: 32.8967\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1266.3990 - mae: 29.6765\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1208.8874 - mae: 29.0439\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1261.2996 - mae: 28.8880\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1205.4474 - mae: 28.8818\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1433.2835 - mae: 29.9641\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 938.9170 - mae: 25.5089\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 996.2474 - mae: 24.8503\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1026.1612 - mae: 24.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:39:23.868025 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024: early stopping\n",
      "2018LG =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:39:24.262969 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1128327308.5146 - mae: 18629.6172\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 201761.8064 - mae: 306.6222\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 17461.5536 - mae: 110.8059\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 19181.5952 - mae: 113.9464\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 13958.0118 - mae: 97.8056\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 13075.9366 - mae: 92.8456\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 14782.5407 - mae: 100.32891s - loss: 187\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 19019.9385 - mae: 103.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:39:35.989603 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "2018HH =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:39:36.560076 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1786960983.9295 - mae: 23159.5469\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 702133.7003 - mae: 670.1278\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 325823.6974 - mae: 464.0893\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 231591.3423 - mae: 394.5201\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 98719.4353 - mae: 254.55311s - loss: 100248.5\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 60110.7940 - mae: 199.5254\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 43398.2314 - mae: 171.7337\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 28777.3613 - mae: 135.64880s - loss: 28675.2148 - mae: 134.\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 22203.1422 - mae: 126.7004\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 25845.5172 - mae: 131.10021s - loss: 29072.\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 17297.0855 - mae: 106.2561\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 9881.6067 - mae: 77.4261\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 11133.6347 - mae: 81.6373\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 31ms/sample - loss: 7509.8852 - mae: 71.8199\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 8855.0891 - mae: 70.9668\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 5833.0776 - mae: 60.5442\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 5138.8305 - mae: 58.3487\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3808.1517 - mae: 47.3131\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 5379.5283 - mae: 57.7688\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2476.9148 - mae: 40.7265\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 3226.5057 - mae: 46.4527\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1936.4865 - mae: 37.35120s - loss: 1829.2534 - mae: 36.130\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 2227.1294 - mae: 38.8582\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1534.2138 - mae: 32.3693\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1133.0045 - mae: 27.0687\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1079.0678 - mae: 25.2441s - lo\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 926.7823 - mae: 25.0580\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1597.6025 - mae: 33.7323\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 594.0134 - mae: 19.8190\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 694.2247 - mae: 21.7810\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 308.2343 - mae: 14.2103\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 343.8760 - mae: 14.8135\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 519.6945 - mae: 18.8837s - loss:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:40:27.529742 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00033: early stopping\n",
      "2018NC =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:40:27.807000 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 7615547878.2039 - mae: 45176.2969\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2696395.8865 - mae: 1259.1366s - loss: 458\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 341516.8297 - mae: 494.3333\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 207090.5988 - mae: 364.7964\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 197892.6398 - mae: 353.0329\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 67447.0524 - mae: 215.7269\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 33869.8292 - mae: 144.3447\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 30267.8896 - mae: 141.5708\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 12847.3168 - mae: 87.7326\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 12980.4128 - mae: 88.2178\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 10375.4276 - mae: 84.1200s - loss: 10520.5771\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 7656.6902 - mae: 70.4055\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 7741.5328 - mae: 68.1640\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 7141.9763 - mae: 68.6759\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 5081.2603 - mae: 59.5437\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 7548.0161 - mae: 68.9050\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 7348.1578 - mae: 68.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:40:47.584100 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "2018HT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:40:47.892276 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 3071810257.0466 - mae: 30014.2637\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 831132.3200 - mae: 548.8284 0s - loss: 322535\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 41728.6196 - mae: 173.21750s - loss: 41592.5\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 25870.0698 - mae: 133.17570s - loss: 30491.8328 \n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 19092.6700 - mae: 114.9676\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 15689.0676 - mae: 105.1227\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 8290.4649 - mae: 73.3554\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5127.5263 - mae: 57.3801\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 2419.6330 - mae: 39.099 - 1s 18ms/sample - loss: 2348.7202 - mae: 38.5035\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 1701.5256 - mae: 31.7025\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 655.9863 - mae: 20.8124s - loss: 673.7099 - mae: 21.08\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 457.6688 - mae: 16.3349\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 255.8869 - mae: 12.5458\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 196.4090 - mae: 11.5339\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 184.2478 - mae: 10.5047\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 164.1261 - mae: 10.0313\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 147.3836 - mae: 9.6537\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 103.1971 - mae: 8.2474 - loss: \n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 98.2871 - mae: 7.5449\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 200.2640 - mae: 11.6959\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 183.4026 - mae: 11.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:17.180935 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n",
      "2018SK =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:17.726475 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 786272819.4224 - mae: 13509.37990s - loss: 1465476355.1266  - ETA: 0s - loss: 831798170.7900 - mae: 14250.75\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 216293.6182 - mae: 283.9963\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 598.5346 - mae: 19.0476 0s \n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 33ms/sample - loss: 235.6560 - mae: 13.3827\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 261.9794 - mae: 13.4737\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 326.1698 - mae: 14.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:30.021593 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "2018KT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:30.677832 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 35ms/sample - loss: 833020676.3083 - mae: 13936.76950s - loss: 1146552073.9627 - m\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 66009.4530 - mae: 173.3800\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 3995.2980 - mae: 49.82781s - loss: 4823.845\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 2243.9242 - mae: 38.3227\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 28ms/sample - loss: 1362.2598 - mae: 29.8397\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 449.4831 - mae: 17.6419\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 289.6011 - mae: 13.9746\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 110.9532 - mae: 8.20050s - loss: 138.8832 - mae: 9. - ETA: 0s - loss: 128.1696 - mae: \n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 21ms/sample - loss: 40.0399 - mae: 5.0630\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 34.1140 - mae: 4.7586\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 26.0097 - mae: 4.2906\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 22.3195 - mae: 3.9153\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 21.3674 - mae: 3.7501\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 15.3451 - mae: 3.1596\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 19.9609 - mae: 3.5985\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 18.3412 - mae: 3.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:57.558930 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "2018WO =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:41:57.941908 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1715827147.5912 - mae: 21366.0391\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 118045.9945 - mae: 229.2151\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5653.9335 - mae: 55.6258\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 3500.9520 - mae: 44.0599\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2421.0782 - mae: 36.7508\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1256.4842 - mae: 27.1475\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 746.0188 - mae: 21.5521\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 486.9841 - mae: 17.7409\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 315.4664 - mae: 14.3902\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 340.0901 - mae: 15.8670\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 230.7863 - mae: 12.2606\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 168.7931 - mae: 10.3752\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 192.5337 - mae: 11.4915\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 186.7979 - mae: 11.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:42:14.795825 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "2018LT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:42:15.109984 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 6756880257.1189 - mae: 47013.5781\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 5428283.7113 - mae: 1442.1217\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 8028.7140 - mae: 70.44960s - loss: 7395.8516 - mae: 65.\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 7389.5745 - mae: 70.52910s - loss: 9237.0144 - mae\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 6146.0662 - mae: 61.9695\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 5766.7155 - mae: 60.7278\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 6817.1537 - mae: 67.3213\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 5331.6935 - mae: 59.1852\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 6162.0607 - mae: 62.1609\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 6612.2580 - mae: 65.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:42:27.700310 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "2018SS =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:42:28.045385 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5284810743.1076 - mae: 36770.8086\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 2397431.7750 - mae: 1140.1906\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 294622.7813 - mae: 445.0179\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 250280.9390 - mae: 397.8328\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 198169.3592 - mae: 350.3642\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 157469.7130 - mae: 332.7360\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 80872.9680 - mae: 222.8800\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 76418.5857 - mae: 220.4492\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 60069.3768 - mae: 191.682 - 1s 20ms/sample - loss: 58131.4483 - mae: 187.9115\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 34431.9585 - mae: 148.3307\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 25668.1443 - mae: 131.0398\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 20112.5492 - mae: 108.13490s - loss: 20081.9505 -\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 14393.1757 - mae: 98.8877\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 10448.6547 - mae: 82.0105\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 7772.9043 - mae: 72.0567\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 6496.4819 - mae: 61.4654\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 4693.7287 - mae: 55.4014\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 4215.9080 - mae: 52.0643\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1909.5355 - mae: 34.8330\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 1794.7901 - mae: 34.7436\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 887.5321 - mae: 23.7011\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 635.3385 - mae: 21.0533\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 361.2090 - mae: 15.1645\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 352.0152 - mae: 15.2987\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 382.3400 - mae: 16.7009\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 231.5024 - mae: 12.4072\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 200.7856 - mae: 11.5359\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 2s 33ms/sample - loss: 162.0183 - mae: 10.2942\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 2s 33ms/sample - loss: 209.5595 - mae: 11.7448\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 115.8827 - mae: 8.7105\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 219.0143 - mae: 11.8976\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 144.2739 - mae: 10.0227s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:20.174952 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032: early stopping\n",
      "2018OB =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:20.923946 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 3245426633.4197 - mae: 33740.8750\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 723425.4235 - mae: 529.3049\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 2906.9895 - mae: 46.6934\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2128.0024 - mae: 38.1576\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 1871.1050 - mae: 34.61960s - loss: 1295.6949 \n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 1206.7236 - mae: 27.3723\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1578.8139 - mae: 32.2020\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1110.5119 - mae: 25.5738\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 1049.4784 - mae: 26.0177\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1046.0388 - mae: 24.7039\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 894.4857 - mae: 22.9563\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1157.6830 - mae: 27.1718 - loss: 989.7987 - mae:\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 1033.6454 - mae: 25.1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:39.186096 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "2019LG =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:39.538155 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1111649155.8920 - mae: 19911.1055\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 624192.5912 - mae: 598.9373\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 8751.5015 - mae: 71.1747\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 4921.2428 - mae: 57.5918\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 5949.8530 - mae: 63.5236\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 5037.5223 - mae: 57.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:47.022136 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "2019HH =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:43:47.340286 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 269625961507.1648 - mae: 258632.6250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 137000508.7815 - mae: 7916.2725\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 4600996.7085 - mae: 1749.2253\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 4321364.4140 - mae: 1600.9673\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 3635143.7739 - mae: 1495.4463\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 3171736.0860 - mae: 1416.0981\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 2321878.2594 - mae: 1159.5607\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2352965.2807 - mae: 1130.9050s - loss: 2411740.2175 - mae: 1140.\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1635634.1956 - mae: 948.5378\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1592627.7741 - mae: 1001.9074\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 888224.9966 - mae: 764.3059\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1340933.5717 - mae: 893.04410s - loss: 1341345.6017 - mae: 888.106\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 876114.3564 - mae: 722.4675\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 1209078.0043 - mae: 834.1740\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 613296.7561 - mae: 572.5794\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 637542.6909 - mae: 600.3513\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 549391.7169 - mae: 606.4918\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 424725.5213 - mae: 504.3076\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 400898.9411 - mae: 496.1716\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 351891.3465 - mae: 443.2314\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 389293.4495 - mae: 498.6853\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 444710.4736 - mae: 528.6860s - loss: 440366.3885 - mae: 528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:44:15.737331 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022: early stopping\n",
      "2019NC =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:44:16.127285 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4996783610.9968 - mae: 39154.3164\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2196915.7967 - mae: 1040.8241\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 59470.9745 - mae: 178.5154\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 17429.9538 - mae: 106.7902\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 9307.6829 - mae: 79.7863\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 4170.3479 - mae: 52.5922\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1749.1774 - mae: 33.2413\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 860.1414 - mae: 23.1612\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 328.6376 - mae: 15.0531\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 135.8942 - mae: 9.5764\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 48.1809 - mae: 5.5557\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 21.0237 - mae: 3.4670\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 8.7593 - mae: 2.3904\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 6.6484 - mae: 2.01080s - loss: 6.3672 - ma\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 5.1659 - mae: 1.8132\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 5.1606 - mae: 1.8548\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 6.0815 - mae: 2.0301\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 2s 30ms/sample - loss: 5.5396 - mae: 1.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:44:46.609753 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: early stopping\n",
      "2019HT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:44:47.158285 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 3527459990.1409 - mae: 28278.9844s - loss: 8190065 - ETA: 0s - loss: 4359457966.0624 - m\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 1530912.1876 - mae: 730.1581\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 33ms/sample - loss: 70674.7393 - mae: 210.2107\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 72744.9911 - mae: 228.2987\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 35245.9488 - mae: 150.8502\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 33503.3659 - mae: 150.32400s - loss: 224\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 30229.5772 - mae: 138.71580s - loss: 34714.7563 - mae: 14 - ETA: 0s - loss: 30739.5127 - mae: 139.49\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 29728.8840 - mae: 134.8691\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 34739.0340 - mae: 158.1404\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 22948.7763 - mae: 122.1267\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 27049.9023 - mae: 130.74520s - loss: 31298.2067 - mae: 1\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 21836.4473 - mae: 117.4007\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 22997.4981 - mae: 126.4816\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 16161.1611 - mae: 104.9325\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 24942.8250 - mae: 121.43650s - loss: 17506.8705 - mae: 107.9\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 20980.0159 - mae: 118.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:45:13.413058 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "2019SK =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:45:13.762123 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 911049087.9403 - mae: 15697.4062\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 1105647.2311 - mae: 807.2250\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 69641.8841 - mae: 211.8744\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 58764.0038 - mae: 192.5993\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 44996.1997 - mae: 179.7380\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 39535.7388 - mae: 162.0698\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 18546.4043 - mae: 113.6803\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 12482.4029 - mae: 89.5792\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 14ms/sample - loss: 14614.8455 - mae: 91.4164\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 10566.5964 - mae: 79.8943\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 6533.5370 - mae: 61.4792\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 8828.8931 - mae: 67.98470s - loss: 6762.9066 - mae: 5\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 30655.0767 - mae: 141.3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:45:29.645640 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "2019KT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:45:30.048562 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 2356917374.7311 - mae: 23260.9648\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 315792.9655 - mae: 468.3446\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 191946.0144 - mae: 342.5248\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 174286.7600 - mae: 334.2165\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 125151.8395 - mae: 289.0731\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 78792.3518 - mae: 232.3116\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 51755.4512 - mae: 192.7279\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 59885.9575 - mae: 207.4907\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 39679.4772 - mae: 157.8852\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 26437.4838 - mae: 133.1701\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 16617.7647 - mae: 109.3979\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 12622.6280 - mae: 91.5698\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 9996.4422 - mae: 84.5276\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 6769.6980 - mae: 66.7505\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 4587.1844 - mae: 54.6206\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 7021.9383 - mae: 71.32910s - loss: 7414.0841 - m\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 3590.4544 - mae: 50.8877\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 2655.8330 - mae: 40.8483\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 2569.1433 - mae: 39.5152\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 2369.2734 - mae: 39.1965\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 2156.1010 - mae: 37.2893\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 1859.6090 - mae: 34.08431s - loss: 20\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3099.5888 - mae: 45.39660s - loss: 3215.3300 - mae: 46.3\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 1695.2699 - mae: 33.50341s - loss: 1898.819\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 2004.9319 - mae: 36.8168\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 1335.9307 - mae: 28.52050s - loss: 1416.9269 - mae:\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 1258.7306 - mae: 29.63161s - loss\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 1303.1040 - mae: 29.1381\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 2s 25ms/sample - loss: 1553.5835 - mae: 31.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:13.217095 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: early stopping\n",
      "2019WO =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:14.079788 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 26ms/sample - loss: 26289211468.2017 - mae: 94287.7344\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 17384400.8084 - mae: 2618.73291s - loss: 84614940\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 1022638.0465 - mae: 857.86650s - loss: 1085650.6257 - mae: 880.\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 759795.2415 - mae: 729.3528\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 888865.2404 - mae: 762.3014\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 2s 22ms/sample - loss: 965733.1755 - mae: 818.0502\n",
      "Epoch 00006: early stopping"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:25.375572 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019LT =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:25.960009 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 2438910820.7778 - mae: 27010.9082\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 48308.9794 - mae: 170.72740s - loss: 58398.8692 - mae: 191.985 - ETA: 0s - loss: 55939.5618 - mae: 186\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 9179.3294 - mae: 77.3629\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 6480.2010 - mae: 69.1018\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 5777.8873 - mae: 61.1196\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 5309.8611 - mae: 61.1296\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 5622.8117 - mae: 62.3445\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 4904.3188 - mae: 57.2354\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 5256.8093 - mae: 62.0914- ETA: 0s - loss: 3520.1930 - 1s 17ms/sample - loss: 5285.4888 - mae: 61.9682\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 5629.8359 - mae: 63.6499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:39.417013 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "2019SS =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:39.736160 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 942838738.4292 - mae: 14264.5586\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 86343.5122 - mae: 236.3664\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 32477.1554 - mae: 146.7305\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 27380.5714 - mae: 131.9543\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 24254.3730 - mae: 114.5938\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 15ms/sample - loss: 29050.6616 - mae: 149.1188\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 13165.2417 - mae: 90.3701\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 13122.5207 - mae: 94.8863\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 12589.2309 - mae: 93.2542\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 14054.6115 - mae: 94.1134\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 9125.8956 - mae: 72.6822\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 16ms/sample - loss: 11895.0144 - mae: 89.8172\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 10230.2640 - mae: 78.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:56.809492 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "2019OB =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:46:57.281229 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              59392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,258,817\n",
      "Trainable params: 4,258,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73 samples\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3187005697.8070 - mae: 33582.8984\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 6320923.3241 - mae: 1570.0564\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 11851.4056 - mae: 84.4984\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 4785.5662 - mae: 58.5748\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 3902.9063 - mae: 51.66881s - loss: 57\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 3385.0439 - mae: 49.52910s - loss: 3442.0960 - mae: 4\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 18ms/sample - loss: 2665.9873 - mae: 43.4332\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 17ms/sample - loss: 2198.0696 - mae: 39.4685\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 1739.8157 - mae: 35.2399\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 1447.2294 - mae: 32.1089\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 1220.2021 - mae: 29.9633\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 923.1702 - mae: 25.3470\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 19ms/sample - loss: 817.9891 - mae: 23.6825\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 20ms/sample - loss: 614.3302 - mae: 21.2556\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 510.5249 - mae: 19.3814s - loss: 378.7333 - mae: 16.10 - ETA: 1s\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 396.1502 - mae: 16.12 - ETA: 0s - loss: 405.0062 - mae: 16.40 - ETA: 0s - loss: 414.4136 - mae: 16.62 - 2s 22ms/sample - loss: 440.4213 - mae: 17.2239\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 403.4589 - mae: 16.9796\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 2s 21ms/sample - loss: 407.2213 - mae: 17.0826\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 361.5229 - mae: 15.7872\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 2s 32ms/sample - loss: 332.6742 - mae: 14.8478\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 2s 23ms/sample - loss: 343.4329 - mae: 15.2591\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 322.1596 - mae: 14.3431\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 2s 24ms/sample - loss: 270.6866 - mae: 13.3174\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 327.1908 - mae: 15.2026s - loss: 360.082\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 3s 41ms/sample - loss: 248.6516 - mae: 12.7993\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 2s 29ms/sample - loss: 322.9174 - mae: 15.0691\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 2s 27ms/sample - loss: 316.8019 - mae: 14.5823s - loss: 327.0984 - ma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 18:47:42.745622 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027: early stopping\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['shift_AVG_2', 'shift_AVG_1'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-7afffe781a27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mtest_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y_pred'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"shift_AVG_1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"shift_AVG_2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MSE_avg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y_pred'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"shift_AVG_1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"shift_AVG_2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MSE_avg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['shift_AVG_2', 'shift_AVG_1'] not in index\""
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred','MSE','MSE_avg'])\n",
    "\n",
    "idx = 0\n",
    "for y in year:\n",
    "    tmp1 = PCT_x_train[PCT_x_train[\"YEAR\"] == y]\n",
    "    tmp2 = PCT_y_train[PCT_y_train[\"YEAR\"] == y]\n",
    "    tmp3 = PCT_x_test[PCT_x_test[\"YEAR\"] == y]\n",
    "    tmp4 = PCT_y_test[PCT_y_test[\"YEAR\"] == y]\n",
    "    for t in team:\n",
    "        name = '{}{}'.format(y,t)\n",
    "        print(name,\"=======================================\")\n",
    "        \n",
    "        X_train = tmp1[tmp1[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "        y_train = tmp2[tmp2[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        X_test = tmp3[tmp3[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        y_test = tmp4[tmp4[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        \n",
    "        X_train_v = X_train.values\n",
    "        y_train_v = y_train.values\n",
    "\n",
    "        X_test_v = X_test.values\n",
    "        y_test_v = y_test.values\n",
    "        \"\"\"\n",
    "        X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,X_train_v.shape[1]//2)\n",
    "        X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,X_test_v.shape[1]//2)\n",
    "        \"\"\"\n",
    "        \n",
    "        ## model\n",
    "        K.clear_session() \n",
    "        \n",
    "        model = Sequential()\n",
    "        optimizer = Adam(lr=0.01)\n",
    "        model.add(Dense(1024, input_shape = [X_train.shape[1]]))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dense(1)) # output = 1\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "       \n",
    "        model.summary()\n",
    "        \n",
    "        #early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "        hist1 = model.fit(X_train, y_train, epochs=100,\n",
    "                  batch_size=1, verbose=1, callbacks=[early_stop])\n",
    "        ##\n",
    "        \n",
    "        model_dict[name] = model\n",
    "        hist_dict[name] = hist1\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        ######### MSE AVG#########\n",
    "        mse_avg = mean_squared_error(y_test,[y_train.mean()[0]])\n",
    "        \n",
    "        \n",
    "        test_pred_df.loc[idx,:] = [y,t,y_test_v.reshape(-1)[0],y_pred.reshape(-1)[0], mse,mse_avg]\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "test_pred_df[['y','y_pred',\"shift_AVG_1\",\"shift_AVG_2\",'MSE','MSE_avg']] = test_pred_df[['y','y_pred',\"shift_AVG_1\",\"shift_AVG_2\",'MSE','MSE_avg']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 PCT모델3 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-118.827</td>\n",
       "      <td>14264.8</td>\n",
       "      <td>0.0198898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>133.132</td>\n",
       "      <td>17591.4</td>\n",
       "      <td>0.00188918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>356.55</td>\n",
       "      <td>126725</td>\n",
       "      <td>0.00236344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>-54.6275</td>\n",
       "      <td>3034.45</td>\n",
       "      <td>0.00177981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>152.424</td>\n",
       "      <td>23093.6</td>\n",
       "      <td>1.59635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>171.931</td>\n",
       "      <td>29460.1</td>\n",
       "      <td>0.00425478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>70.5611</td>\n",
       "      <td>4926.08</td>\n",
       "      <td>0.0412888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.602209</td>\n",
       "      <td>1.21486</td>\n",
       "      <td>0.0023538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32.8056</td>\n",
       "      <td>1043.65</td>\n",
       "      <td>0.00601803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-39.5171</td>\n",
       "      <td>1614.73</td>\n",
       "      <td>0.00438377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-4.10075</td>\n",
       "      <td>20.571</td>\n",
       "      <td>0.00258055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-29.9093</td>\n",
       "      <td>920.761</td>\n",
       "      <td>0.000555806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-41.9676</td>\n",
       "      <td>1803.5</td>\n",
       "      <td>0.00312884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>56.3025</td>\n",
       "      <td>3113.92</td>\n",
       "      <td>0.0126323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-8.17171</td>\n",
       "      <td>77.3822</td>\n",
       "      <td>0.0144864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>146.865</td>\n",
       "      <td>21422.6</td>\n",
       "      <td>0.0582925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>-210.941</td>\n",
       "      <td>44642.8</td>\n",
       "      <td>0.0358436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-266.634</td>\n",
       "      <td>71449.7</td>\n",
       "      <td>0.0211527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>353.548</td>\n",
       "      <td>124720</td>\n",
       "      <td>0.0092804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-36.7204</td>\n",
       "      <td>1391.57</td>\n",
       "      <td>0.00171549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-112.974</td>\n",
       "      <td>12857.3</td>\n",
       "      <td>0.00635766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19.4163</td>\n",
       "      <td>357.825</td>\n",
       "      <td>0.00366053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>102.559</td>\n",
       "      <td>10433.1</td>\n",
       "      <td>0.000312202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>9.35256</td>\n",
       "      <td>77.6318</td>\n",
       "      <td>0.00684964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>14.5509</td>\n",
       "      <td>198.6</td>\n",
       "      <td>0.00524381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-2.47943</td>\n",
       "      <td>8.24112</td>\n",
       "      <td>0.000626987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>-16.494</td>\n",
       "      <td>290.213</td>\n",
       "      <td>0.00105848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>28.7413</td>\n",
       "      <td>788.184</td>\n",
       "      <td>0.0457065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>-10.9805</td>\n",
       "      <td>132.302</td>\n",
       "      <td>4.1283e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625</td>\n",
       "      <td>54.0712</td>\n",
       "      <td>2856.49</td>\n",
       "      <td>9.4152e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>-122.539</td>\n",
       "      <td>15148.8</td>\n",
       "      <td>2.66442e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-1178.49</td>\n",
       "      <td>1.39021e+06</td>\n",
       "      <td>0.0656787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>-15.0977</td>\n",
       "      <td>245.327</td>\n",
       "      <td>0.0124046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>260.59</td>\n",
       "      <td>67647</td>\n",
       "      <td>0.000390213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.375</td>\n",
       "      <td>180.691</td>\n",
       "      <td>32514</td>\n",
       "      <td>0.0814464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>5.55572</td>\n",
       "      <td>25.1407</td>\n",
       "      <td>0.000219495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-615.761</td>\n",
       "      <td>379983</td>\n",
       "      <td>0.0034855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>97.3999</td>\n",
       "      <td>9446.2</td>\n",
       "      <td>0.0280416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.494453</td>\n",
       "      <td>0.00605068</td>\n",
       "      <td>0.000980832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>-54.5048</td>\n",
       "      <td>3042.29</td>\n",
       "      <td>0.00948275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred          MSE      MSE_avg\n",
       "0   2016   LG  0.608696  -118.827      14264.8    0.0198898\n",
       "1   2016   HH       0.5   133.132      17591.4   0.00188918\n",
       "2   2016   NC  0.565217    356.55       126725   0.00236344\n",
       "3   2016   HT  0.458333  -54.6275      3034.45   0.00177981\n",
       "4   2016   SK  0.458333   152.424      23093.6  1.59635e-05\n",
       "5   2016   KT  0.291667   171.931      29460.1   0.00425478\n",
       "6   2016   WO     0.375   70.5611      4926.08    0.0412888\n",
       "7   2016   LT       0.5 -0.602209      1.21486    0.0023538\n",
       "8   2016   SS       0.5   32.8056      1043.65   0.00601803\n",
       "9   2016   OB  0.666667  -39.5171      1614.73   0.00438377\n",
       "10  2017   LG  0.434783  -4.10075       20.571   0.00258055\n",
       "11  2017   HH  0.434783  -29.9093      920.761  0.000555806\n",
       "12  2017   NC       0.5  -41.9676       1803.5   0.00312884\n",
       "13  2017   HT       0.5   56.3025      3113.92    0.0126323\n",
       "14  2017   SK     0.625  -8.17171      77.3822    0.0144864\n",
       "15  2017   KT       0.5   146.865      21422.6    0.0582925\n",
       "16  2017   WO  0.347826  -210.941      44642.8    0.0358436\n",
       "17  2017   LT  0.666667  -266.634      71449.7    0.0211527\n",
       "18  2017   SS  0.391304   353.548       124720    0.0092804\n",
       "19  2017   OB  0.583333  -36.7204      1391.57   0.00171549\n",
       "20  2018   LG  0.416667  -112.974      12857.3   0.00635766\n",
       "21  2018   HH       0.5   19.4163      357.825   0.00366053\n",
       "22  2018   NC  0.416667   102.559      10433.1  0.000312202\n",
       "23  2018   HT  0.541667   9.35256      77.6318   0.00684964\n",
       "24  2018   SK  0.458333   14.5509        198.6   0.00524381\n",
       "25  2018   KT  0.391304  -2.47943      8.24112  0.000626987\n",
       "26  2018   WO  0.541667   -16.494      290.213   0.00105848\n",
       "27  2018   LT  0.666667   28.7413      788.184    0.0457065\n",
       "28  2018   SS  0.521739  -10.9805      132.302   4.1283e-05\n",
       "29  2018   OB     0.625   54.0712      2856.49   9.4152e-05\n",
       "30  2019   LG  0.541667  -122.539      15148.8  2.66442e-05\n",
       "31  2019   HH  0.583333  -1178.49  1.39021e+06    0.0656787\n",
       "32  2019   NC  0.565217  -15.0977      245.327    0.0124046\n",
       "33  2019   HT       0.5    260.59        67647  0.000390213\n",
       "34  2019   SK     0.375   180.691        32514    0.0814464\n",
       "35  2019   KT  0.541667   5.55572      25.1407  0.000219495\n",
       "36  2019   WO  0.666667  -615.761       379983    0.0034855\n",
       "37  2019   LT  0.208333   97.3999       9446.2    0.0280416\n",
       "38  2019   SS  0.416667  0.494453   0.00605068  0.000980832\n",
       "39  2019   OB  0.652174  -54.5048      3042.29   0.00948275"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR        2017.500000\n",
       "y              0.500951\n",
       "y_pred       -17.344830\n",
       "MSE        60439.437788\n",
       "MSE_avg        0.012900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AVG 모델\n",
    "<p>AVG를 예측하기 위한 모델</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 AVG모델1\n",
    "<p>기본 데이터셋에서 가지고 있는 모든 Column 데이터를 사용해서 AVG를 예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=pd.read_csv(\"PCT\\\\PCT_train_x.csv\")\n",
    "PCT_y_train=pd.read_csv(\"PCT\\\\PCT_train_y.csv\")\n",
    "PCT_x_test=pd.read_csv(\"PCT\\\\PCT_test_x.csv\")\n",
    "PCT_y_test=pd.read_csv(\"PCT\\\\PCT_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 데이터 전처리\n",
    "<p>Training 과 Prediction에서 불필요한 T_ID, YEAR, shift_HEADER_NO를 제거하였다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_x_train=PCT_x_train.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "PCT_x_test=PCT_x_test.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "PCT_y_train=PCT_y_train.drop(columns=[\"T_ID\", \"YEAR\"])\n",
    "#PCT_y_test=PCT_y_test.drop(columns=[\"T_ID\", \"YEAR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 PCT모델1 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(PCT_x_train.keys())]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 10 == 0: print('')\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 17:50:54.591986 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                3712      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "..........\n",
      "..........\n",
      "..........\n",
      ".....Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "EPOCHS = 100\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "  PCT_x_train, PCT_y_train,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot(), early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 PCT모델1 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 17:53:03.325359 15596 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>PCT</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HH</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.436020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.406186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.538021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.571580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.546638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.451373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OB</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.510216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.482959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SS</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.707297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HH</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.496931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.441289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.478370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.517712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.559464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.480857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.610305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.574359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WO</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.528751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HH</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.502226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.421338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.577664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.426085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.541177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OB</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.383414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.528359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.553028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WO</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.561610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HH</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.280141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.471881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.339698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.440740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.513179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.500015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.508969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SS</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.435094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WO</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.462574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HH</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.576774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.604758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.443191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LG</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.534709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.517156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NC</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.526948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OB</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.519766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.424915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.490312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WO</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.545433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       PCT    y_pred\n",
       "0    HH  2016  0.500000  0.436020\n",
       "1    HT  2016  0.458333  0.406186\n",
       "2    KT  2016  0.291667  0.538021\n",
       "3    LG  2016  0.608696  0.571580\n",
       "4    LT  2016  0.500000  0.546638\n",
       "5    NC  2016  0.565217  0.451373\n",
       "6    OB  2016  0.666667  0.510216\n",
       "7    SK  2016  0.458333  0.482959\n",
       "8    SS  2016  0.500000  0.707297\n",
       "9    WO  2016  0.375000  0.545837\n",
       "10   HH  2017  0.434783  0.496931\n",
       "11   HT  2017  0.500000  0.441289\n",
       "12   KT  2017  0.500000  0.484115\n",
       "13   LG  2017  0.434783  0.478370\n",
       "14   LT  2017  0.666667  0.517712\n",
       "15   NC  2017  0.500000  0.559464\n",
       "16   OB  2017  0.583333  0.480857\n",
       "17   SK  2017  0.625000  0.610305\n",
       "18   SS  2017  0.391304  0.574359\n",
       "19   WO  2017  0.347826  0.528751\n",
       "20   HH  2018  0.500000  0.564588\n",
       "21   HT  2018  0.541667  0.502226\n",
       "22   KT  2018  0.391304  0.421338\n",
       "23   LG  2018  0.416667  0.577664\n",
       "24   LT  2018  0.666667  0.426085\n",
       "25   NC  2018  0.416667  0.541177\n",
       "26   OB  2018  0.625000  0.383414\n",
       "27   SK  2018  0.458333  0.528359\n",
       "28   SS  2018  0.521739  0.553028\n",
       "29   WO  2018  0.541667  0.561610\n",
       "30   HH  2019  0.583333  0.280141\n",
       "31   HT  2019  0.500000  0.552239\n",
       "32   KT  2019  0.541667  0.471881\n",
       "33   LG  2019  0.541667  0.339698\n",
       "34   LT  2019  0.208333  0.440740\n",
       "35   NC  2019  0.565217  0.513179\n",
       "36   OB  2019  0.652174  0.500015\n",
       "37   SK  2019  0.375000  0.508969\n",
       "38   SS  2019  0.416667  0.435094\n",
       "39   WO  2019  0.666667  0.462574\n",
       "40   HH  2020  0.291667  0.576774\n",
       "41   HT  2020  0.500000  0.604758\n",
       "42   KT  2020  0.608696  0.443191\n",
       "43   LG  2020  0.391304  0.534709\n",
       "44   LT  2020  0.458333  0.517156\n",
       "45   NC  2020  0.681818  0.526948\n",
       "46   OB  2020  0.583333  0.519766\n",
       "47   SK  2020  0.375000  0.424915\n",
       "48   SS  2020  0.625000  0.490312\n",
       "49   WO  2020  0.541667  0.545433"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(PCT_x_test)\n",
    "PCT_y_test['y_pred']=y_pred\n",
    "PCT_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01872916238939003"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(PCT_y_test['PCT'], y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11193741650213836"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(PCT_y_test['PCT'], y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "success=0\n",
    "fail=0\n",
    "for idx in PCT_y_test.index:\n",
    "    if(PCT_y_test['PCT'][idx] <PCT_y_test['y_pred'][idx]+mae and PCT_y_test['PCT'][idx] >PCT_y_test['y_pred'][idx]-mae ):\n",
    "        success+=1\n",
    "    else:\n",
    "        fail+=1\n",
    "print(success)\n",
    "print(fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 AVG모델1\n",
    "<p>기본 데이터셋에서 가지고 있는 모든 Column 데이터를 사용해서 AVG를 예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_x_train_=pd.read_csv(\"AVG\\\\AVG_train_x.csv\")\n",
    "AVG_y_train=pd.read_csv(\"AVG\\\\AVG_train_y.csv\")\n",
    "AVG_x_test=pd.read_csv(\"AVG\\\\AVG_test_x.csv\")\n",
    "AVG_y_test=pd.read_csv(\"AVG\\\\AVG_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 AVG모델2\n",
    "<p>AVG와 상관관계가 일정 수준 이상이 Column으로만 AVG예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ERA 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 ERA모델1\n",
    "<p>기본 데이터셋에서 가지고 있는 모든 Column 데이터를 사용해서 ERA를 예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA_x_train=pd.read_csv(\"ERA\\\\ERA_train_x.csv\")\n",
    "ERA_y_train=pd.read_csv(\"ERA\\\\ERA_train_y.csv\")\n",
    "ERA_x_test=pd.read_csv(\"ERA\\\\ERA_test_x.csv\")\n",
    "ERA_y_test=pd.read_csv(\"ERA\\\\ERA_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 ERA모델2\n",
    "<p>AVG와 상관관계가 일정 수준 이상이 Column으로만 ERA예측.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
